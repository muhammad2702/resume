{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNviHYzxXmp8OeqIKyQb4BX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muhammad2702/resume/blob/master/Untitled20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wVL6pmZWCOQk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8317a674-c2aa-404f-c98d-5815115d59d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching data for X:LTCUSD - 1minute\n",
            "Saved 25918 records to crypto_data/X_LTCUSD/X_LTCUSD_1minute.csv\n",
            "Fetching data for X:BCHUSD - 1minute\n",
            "Saved 25600 records to crypto_data/X_BCHUSD/X_BCHUSD_1minute.csv\n",
            "Fetching data for X:XRPUSD - 1minute\n",
            "Saved 25918 records to crypto_data/X_XRPUSD/X_XRPUSD_1minute.csv\n",
            "Fetching data for X:XLMUSD - 1minute\n",
            "Saved 25801 records to crypto_data/X_XLMUSD/X_XLMUSD_1minute.csv\n",
            "Fetching data for X:LINKUSD - 1minute\n",
            "Saved 25830 records to crypto_data/X_LINKUSD/X_LINKUSD_1minute.csv\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "import requests\n",
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Configuration\n",
        "API_KEY = 'whXh4oYmhSxw1SYOlu5HZnw6NPTJFOF5'  # Replace with your actual API key\n",
        "BASE_URL = 'https://api.polygon.io/v2/aggs/ticker/{ticker}/range/{multiplier}/{timespan}/{from_date}/{to_date}'\n",
        "\n",
        "# List of cryptocurrencies (tickers) you want to collect data for\n",
        "TICKERS = [\n",
        "\n",
        "\n",
        " 'X:LTCUSD', 'X:BCHUSD', 'X:XRPUSD', 'X:XLMUSD', 'X:LINKUSD'\n",
        "\n",
        "\n",
        "\n",
        "]\n",
        "\n",
        "# Timeframes you want to collect data for\n",
        "TIMEFRAMES = [\n",
        "\n",
        "    {'multiplier': 1, 'timespan': 'minute'},\n",
        "]\n",
        "\n",
        "# Date range for data collection\n",
        "START_DATE = '2024-11-01'\n",
        "END_DATE = '2024-11-18'\n",
        "\n",
        "# Directory to save the collected data\n",
        "DATA_DIR = 'crypto_data'\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "\n",
        "def daterange(start_date, end_date, delta):\n",
        "    current = start_date\n",
        "    while current <= end_date:\n",
        "        yield current\n",
        "        current += delta\n",
        "\n",
        "def fetch_data(ticker, multiplier, timespan, from_date, to_date):\n",
        "    url = BASE_URL.format(\n",
        "        ticker=ticker,\n",
        "        multiplier=multiplier,\n",
        "        timespan=timespan,\n",
        "        from_date=from_date.strftime('%Y-%m-%d'),\n",
        "        to_date=to_date.strftime('%Y-%m-%d')\n",
        "    )\n",
        "    params = {\n",
        "        'adjusted': 'true',\n",
        "        'sort': 'asc',\n",
        "        'limit': '50000',  # Maximum allowed by Polygon.io\n",
        "        'apiKey': API_KEY\n",
        "    }\n",
        "    response = requests.get(url, params=params)\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        return data.get('results', [])\n",
        "    else:\n",
        "        print(f\"Error fetching data for {ticker} - {timespan}: {response.status_code} - {response.text}\")\n",
        "        return []\n",
        "\n",
        "def main():\n",
        "    start = datetime.strptime(START_DATE, '%Y-%m-%d')\n",
        "    end = datetime.strptime(END_DATE, '%Y-%m-%d')\n",
        "\n",
        "    for ticker in TICKERS:\n",
        "        ticker_dir = os.path.join(DATA_DIR, ticker.replace(\":\", \"_\"))\n",
        "        os.makedirs(ticker_dir, exist_ok=True)\n",
        "\n",
        "        for timeframe in TIMEFRAMES:\n",
        "            multiplier = timeframe['multiplier']\n",
        "            timespan = timeframe['timespan']\n",
        "            filename = f\"{ticker.replace(':', '_')}_{multiplier}{timespan}.csv\"\n",
        "            filepath = os.path.join(ticker_dir, filename)\n",
        "\n",
        "            print(f\"Fetching data for {ticker} - {multiplier}{timespan}\")\n",
        "\n",
        "            # To handle large date ranges, you might need to split the requests\n",
        "            # For simplicity, we'll attempt to fetch all data at once\n",
        "            data = fetch_data(ticker, multiplier, timespan, start, end)\n",
        "\n",
        "            if data:\n",
        "                df = pd.DataFrame(data)\n",
        "                # Convert timestamp to datetime\n",
        "                df['t'] = pd.to_datetime(df['t'], unit='ms')\n",
        "                # Save to CSV\n",
        "                df.to_csv(filepath, index=False)\n",
        "                print(f\"Saved {len(df)} records to {filepath}\")\n",
        "            else:\n",
        "                print(f\"No data fetched for {ticker} - {multiplier}{timespan}\")\n",
        "\n",
        "            # Respect API rate limits\n",
        "            time.sleep(1)  # Adjust sleep time based on your rate limits\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data_preprocessor.py\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from ta import trend, momentum, volatility\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "\n",
        "class CryptoDataPreprocessor:\n",
        "    def __init__(self, raw_data_dir='crypto_data', preprocessed_data_dir='preprocessed_data'):\n",
        "        \"\"\"\n",
        "        Initializes the CryptoDataPreprocessor.\n",
        "\n",
        "        :param raw_data_dir: Directory containing raw CSV data.\n",
        "        :param preprocessed_data_dir: Directory to save preprocessed data.\n",
        "        \"\"\"\n",
        "        self.raw_data_dir = raw_data_dir\n",
        "        self.preprocessed_data_dir = preprocessed_data_dir\n",
        "        os.makedirs(self.preprocessed_data_dir, exist_ok=True)\n",
        "        self.label_encoders = {}\n",
        "\n",
        "    def preprocess_file(self, df):\n",
        "        \"\"\"\n",
        "        Applies preprocessing steps to the DataFrame.\n",
        "\n",
        "        :param df: pandas DataFrame with raw data.\n",
        "        :return: Preprocessed DataFrame and label encoders.\n",
        "        \"\"\"\n",
        "        # Ensure 'c', 'h', 'l' columns exist\n",
        "        required_columns = ['c', 'h', 'l']\n",
        "        for col in required_columns:\n",
        "            if col not in df.columns:\n",
        "                raise ValueError(f\"Missing required column: {col}\")\n",
        "\n",
        "        # Compute RSI\n",
        "        rsi = momentum.RSIIndicator(close=df['c'], window=14)\n",
        "        df['RSI'] = rsi.rsi()\n",
        "\n",
        "        # Compute MACD with smoothing\n",
        "        macd = trend.MACD(close=df['c'], window_slow=26, window_fast=12, window_sign=9)\n",
        "        df['MACD'] = macd.macd().rolling(window=3).mean()  # Smoothing\n",
        "        df['MACD_signal'] = macd.macd_signal().rolling(window=3).mean()\n",
        "        df['MACD_diff'] = macd.macd_diff().rolling(window=3).mean()\n",
        "\n",
        "        # Compute ATR\n",
        "        atr = volatility.AverageTrueRange(high=df['h'], low=df['l'], close=df['c'], window=14)\n",
        "        df['ATR'] = atr.average_true_range().rolling(window=3).mean()\n",
        "\n",
        "        # Compute Bollinger Bands Width\n",
        "        bollinger = volatility.BollingerBands(close=df['c'], window=20, window_dev=2)\n",
        "        df['BB_upper'] = bollinger.bollinger_hband().rolling(window=3).mean()\n",
        "        df['BB_lower'] = bollinger.bollinger_lband().rolling(window=3).mean()\n",
        "        df['BB_width'] = ((df['BB_upper'] - df['BB_lower']) / df['c']).rolling(window=3).mean()\n",
        "\n",
        "        # Compute ADX with smoothing\n",
        "        adx = trend.ADXIndicator(high=df['h'], low=df['l'], close=df['c'], window=14)\n",
        "        df['ADX'] = adx.adx().rolling(window=3).mean()\n",
        "\n",
        "        # Drop initial rows with NaN values\n",
        "        df.dropna(inplace=True)\n",
        "\n",
        "        # Classify Market Environments\n",
        "        df, label_encoders = self.classify_market_environments(df)\n",
        "\n",
        "        # Calculate Leg Data\n",
        "        df = self.calculate_leg_data(df)\n",
        "\n",
        "        # Classify Percent Change\n",
        "        df = self.classify_percent_change(df)\n",
        "        df['close_price'] = df['c']  # Assuming 'c' is the closing price\n",
        "\n",
        "        return df, label_encoders\n",
        "\n",
        "    def classify_market_environments(self, df):\n",
        "        \"\"\"\n",
        "        Classify market environments into numerical categories for model training.\n",
        "\n",
        "        :param df: pandas DataFrame with technical indicators.\n",
        "        :return: DataFrame with new classification columns and label encoders.\n",
        "        \"\"\"\n",
        "        # Volatility Classification\n",
        "        df['ATR_mavg'] = df['ATR'].rolling(window=14).mean()\n",
        "        df['ATR_vol'] = np.where(df['ATR'] > 1.2 * df['ATR_mavg'], 'h',\n",
        "                                 np.where(df['ATR'] < 0.8 * df['ATR_mavg'], 'l', 'Medium'))\n",
        "\n",
        "        df['BB_mavg'] = df['BB_width'].rolling(window=20).mean()\n",
        "        df['BB_vol'] = np.where(df['BB_width'] > 1.2 * df['BB_mavg'], 'h',\n",
        "                                np.where(df['BB_width'] < 0.8 * df['BB_mavg'], 'l', 'Medium'))\n",
        "\n",
        "        df['daily_return'] = df['c'].pct_change()\n",
        "        df['RV'] = df['daily_return'].rolling(window=20).std() * np.sqrt(252)\n",
        "        rv_80 = df['RV'].quantile(0.8)\n",
        "        rv_20 = df['RV'].quantile(0.2)\n",
        "        df['RV_vol'] = np.where(df['RV'] > rv_80, 'h',\n",
        "                                np.where(df['RV'] < rv_20, 'l', 'Medium'))\n",
        "\n",
        "        df['Volatility'] = df[['ATR_vol', 'BB_vol', 'RV_vol']].mode(axis=1)[0]\n",
        "\n",
        "        df['Trend'] = np.where(\n",
        "            (df['MACD'] > df['MACD_signal']) & (df['MACD'] > 0), 'Bullish',\n",
        "            np.where(\n",
        "                (df['MACD'] < df['MACD_signal']) & (df['MACD'] < 0), 'Bearish', 'Neutral'\n",
        "            )\n",
        "        )\n",
        "\n",
        "        df['Trend_strength'] = np.where(df['ADX'] > 25, 'Strong', 'Weak')\n",
        "\n",
        "        df['Market_Environment'] = df.apply(\n",
        "            lambda row: f\"{row['Volatility']} Vol/{row['Trend']}\" if row['Trend_strength'] == 'Strong' else f\"{row['Volatility']} Vol/Neutral\",\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "        # Encode categorical data to numeric\n",
        "        label_encoders = {}\n",
        "        categorical_columns = ['ATR_vol', 'BB_vol', 'RV_vol', 'Volatility', 'Trend', 'Trend_strength', 'Market_Environment']\n",
        "        for column in categorical_columns:\n",
        "            le = LabelEncoder()\n",
        "            df[column] = le.fit_transform(df[column].astype(str))\n",
        "            label_encoders[column] = le  # Save encoder for each column if you need to decode later\n",
        "\n",
        "        self.label_encoders = label_encoders  # Store encoders for the instance\n",
        "\n",
        "        return df, label_encoders  # Returning encoders in case needed\n",
        "\n",
        "    def calculate_leg_data(self, df):\n",
        "        df['percent_delta'] = df['c'].pct_change()\n",
        "        df = df.reset_index(drop=True)\n",
        "\n",
        "        previous_leg_change = 0\n",
        "        previous_leg_length = 0\n",
        "        current_leg_change = 0\n",
        "        current_leg_length = 0\n",
        "        current_direction = None\n",
        "\n",
        "        previous_changes = []\n",
        "        previous_lengths = []\n",
        "        current_changes = []\n",
        "        current_lengths = []\n",
        "        leg_directions = []\n",
        "\n",
        "        for i in range(len(df)):\n",
        "            if i == 0:\n",
        "                current_leg_change = 0\n",
        "                current_leg_length = 0\n",
        "                current_direction = 0  # Neutral at start\n",
        "            else:\n",
        "                percent_delta = df.at[i, 'percent_delta']\n",
        "                if current_leg_length == 0:\n",
        "                    current_leg_change = percent_delta\n",
        "                    current_leg_length = 1\n",
        "                    current_direction = 1 if percent_delta > 0 else 0\n",
        "                else:\n",
        "                    # Check if the trend continues\n",
        "                    if (current_leg_change > 0 and percent_delta > 0) or (current_leg_change < 0 and percent_delta < 0):\n",
        "                        current_leg_change += percent_delta\n",
        "                        current_leg_length += 1\n",
        "                    else:\n",
        "                        previous_leg_change = current_leg_change\n",
        "                        previous_leg_length = current_leg_length\n",
        "                        current_leg_change = percent_delta\n",
        "                        current_leg_length = 1\n",
        "                        current_direction = 1 if percent_delta > 0 else 0\n",
        "            previous_changes.append(previous_leg_change)\n",
        "            previous_lengths.append(previous_leg_length)\n",
        "            current_changes.append(current_leg_change)\n",
        "            current_lengths.append(current_leg_length)\n",
        "            leg_directions.append(current_direction)\n",
        "\n",
        "        df['previous_leg_change'] = previous_changes\n",
        "        df['previous_leg_length'] = previous_lengths\n",
        "        df['current_leg_change'] = current_changes\n",
        "        df['current_leg_length'] = current_lengths\n",
        "        df['leg_direction'] = leg_directions  # Add the leg_direction column\n",
        "\n",
        "        df.drop(columns=['percent_delta'], inplace=True)\n",
        "        return df\n",
        "\n",
        "    def classify_percent_change(self, df):\n",
        "        \"\"\"\n",
        "        Classify percent changes into 7 categories.\n",
        "\n",
        "        :param df: pandas DataFrame with gain/loss data.\n",
        "        :return: DataFrame with classification.\n",
        "        \"\"\"\n",
        "        df['percent_change'] = df['c'].pct_change()\n",
        "        df.dropna(inplace=True)\n",
        "\n",
        "        percentiles = df['percent_change'].quantile([0.05, 0.20, 0.40, 0.60, 0.80, 0.95]).to_dict()\n",
        "\n",
        "        def classify(x, p):\n",
        "            if x < p[0.05]:\n",
        "                return 'Down a Lot'\n",
        "            elif x < p[0.20]:\n",
        "                return 'Down Moderate'\n",
        "            elif x < p[0.40]:\n",
        "                return 'Down a Little'\n",
        "            elif x < p[0.60]:\n",
        "                return 'No Change'\n",
        "            elif x < p[0.80]:\n",
        "                return 'Up a Little'\n",
        "            elif x < p[0.95]:\n",
        "                return 'Up Moderate'\n",
        "            else:\n",
        "                return 'Up a Lot'\n",
        "\n",
        "        df['percent_change_classification'] = df['percent_change'].apply(lambda x: classify(x, percentiles))\n",
        "\n",
        "        # Encode the classification\n",
        "        le = LabelEncoder()\n",
        "        df['percent_change_classification'] = le.fit_transform(df['percent_change_classification'].astype(str))\n",
        "        self.label_encoders['percent_change_classification'] = le\n",
        "\n",
        "        return df\n",
        "\n",
        "    def save_preprocessed_data(self, df, filepath):\n",
        "        \"\"\"\n",
        "        Saves the preprocessed DataFrame to a CSV file.\n",
        "\n",
        "        :param df: pandas DataFrame with preprocessed data.\n",
        "        :param filepath: Path where the CSV will be saved.\n",
        "        \"\"\"\n",
        "        df.to_csv(filepath, index=False)\n",
        "        print(f\"Saved preprocessed data to {filepath}\")\n",
        "\n",
        "    def preprocess_all(self):\n",
        "        \"\"\"\n",
        "        Processes all CSV files in the raw data directory and saves the preprocessed data.\n",
        "        \"\"\"\n",
        "        # Traverse the raw_data_dir\n",
        "        for ticker in tqdm(os.listdir(self.raw_data_dir), desc='Processing Tickers'):\n",
        "            ticker_raw_dir = os.path.join(self.raw_data_dir, ticker)\n",
        "            ticker_preprocessed_dir = os.path.join(self.preprocessed_data_dir, ticker)\n",
        "            os.makedirs(ticker_preprocessed_dir, exist_ok=True)\n",
        "\n",
        "            for file in tqdm(os.listdir(ticker_raw_dir), desc=f'Processing {ticker}', leave=False):\n",
        "                if file.endswith('.csv'):\n",
        "                    raw_filepath = os.path.join(ticker_raw_dir, file)\n",
        "                    preprocessed_filename = file.replace('.csv', '_preprocessed.csv')\n",
        "                    preprocessed_filepath = os.path.join(ticker_preprocessed_dir, preprocessed_filename)\n",
        "\n",
        "                    if os.path.exists(preprocessed_filepath):\n",
        "                        print(f\"Preprocessed file already exists: {preprocessed_filepath}. Skipping.\")\n",
        "                        continue\n",
        "\n",
        "                    # Read raw CSV\n",
        "                    try:\n",
        "                        df_raw = pd.read_csv(raw_filepath)\n",
        "                        # Ensure timestamp is datetime if needed\n",
        "                        if 'timestamp' in df_raw.columns and not pd.api.types.is_datetime64_any_dtype(df_raw['timestamp']):\n",
        "                            df_raw['timestamp'] = pd.to_datetime(df_raw['timestamp'])\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error reading {raw_filepath}: {e}\")\n",
        "                        continue\n",
        "\n",
        "                    # Preprocess\n",
        "                    try:\n",
        "                        df_preprocessed, le_encoders = self.preprocess_file(df_raw)\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error preprocessing {raw_filepath}: {e}\")\n",
        "                        continue\n",
        "\n",
        "                    # Save preprocessed data\n",
        "                    self.save_preprocessed_data(df_preprocessed, preprocessed_filepath)\n",
        "\n",
        "        # Save label encoders for future decoding if necessary\n",
        "        self.save_label_encoders()\n",
        "\n",
        "    def save_label_encoders(self, filepath='label_encoders.pkl'):\n",
        "        \"\"\"\n",
        "        Saves the label encoders to a pickle file.\n",
        "\n",
        "        :param filepath: Path to save the encoders.\n",
        "        \"\"\"\n",
        "        with open(filepath, 'wb') as f:\n",
        "            pickle.dump(self.label_encoders, f)\n",
        "        print(f\"Saved label encoders to {filepath}\")\n",
        "\n",
        "def main():\n",
        "    preprocessor = CryptoDataPreprocessor(raw_data_dir='crypto_data', preprocessed_data_dir='preprocessed_data')\n",
        "    preprocessor.preprocess_all()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "4ebR8QF6CTrx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa7cf9ba-d310-4a97-f291-1fd5a0034247"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Tickers:   0%|          | 0/20 [00:00<?, ?it/s]\n",
            "Processing X_DOT:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                                       \u001b[A\n",
            "Processing X_LINK:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                                        \u001b[A\n",
            "Processing X_VET:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                                       \u001b[A\n",
            "Processing X_XRP:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                                       \u001b[A\n",
            "Processing X_XRPUSD:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                                          \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessed file already exists: preprocessed_data/X_XRPUSD/X_XRPUSD_1minute_preprocessed.csv. Skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Processing X_BCHUSDT: 0it [00:00, ?it/s]\u001b[A\n",
            "                                        \u001b[A\n",
            "Processing X_LINKUSDT: 0it [00:00, ?it/s]\u001b[A\n",
            "                                         \u001b[A\n",
            "Processing X_XRPUSDT: 0it [00:00, ?it/s]\u001b[A\n",
            "                                        \u001b[A\n",
            "Processing X_XLMUSDT: 0it [00:00, ?it/s]\u001b[A\n",
            "                                        \u001b[A\n",
            "Processing X_LINKUSD:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                                           \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessed file already exists: preprocessed_data/X_LINKUSD/X_LINKUSD_1minute_preprocessed.csv. Skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Processing X_BCH:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                                       \u001b[A\n",
            "Processing X_BTCUSD:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Processing Tickers:  60%|██████    | 12/20 [00:00<00:00, 114.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessed file already exists: preprocessed_data/X_BTCUSD/X_BTCUSD_1minute_preprocessed.csv. Skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Processing X_BCHUSD:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                                          \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessed file already exists: preprocessed_data/X_BCHUSD/X_BCHUSD_1minute_preprocessed.csv. Skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Processing X_LTC:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                                       \u001b[A\n",
            "Processing X_LTCUSD:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                                          \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessed file already exists: preprocessed_data/X_LTCUSD/X_LTCUSD_1minute_preprocessed.csv. Skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Processing X_LTCUSDT: 0it [00:00, ?it/s]\u001b[A\n",
            "                                        \u001b[A\n",
            "Processing X_ADA:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                                       \u001b[A\n",
            "Processing X_XLMUSD:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                                          \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessed file already exists: preprocessed_data/X_XLMUSD/X_XLMUSD_1minute_preprocessed.csv. Skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Processing X_ETHUSD:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                                          \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessed file already exists: preprocessed_data/X_ETHUSD/X_ETHUSD_1minute_preprocessed.csv. Skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Processing X_XLM:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Processing Tickers: 100%|██████████| 20/20 [00:00<00:00, 115.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved label encoders to label_encoders.pkl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Uz9kK9unDh6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ta"
      ],
      "metadata": {
        "id": "lDDRzOr-CkuO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4af148e6-b289-4231-9b00-34903dc99345"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ta in /usr/local/lib/python3.10/dist-packages (0.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ta) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from ta) (2.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->ta) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ta) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->ta) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->ta) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "class ShortTermTransformerModel(nn.Module):\n",
        "    def __init__(self, num_features, num_cryptos, d_model=256, nhead=8, num_encoder_layers=4,\n",
        "                 dim_feedforward=512, dropout=0.3, num_classes=3, max_seq_length=50):\n",
        "        super(ShortTermTransformerModel, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.crypto_embedding = nn.Embedding(num_cryptos, d_model)\n",
        "        self.input_linear = nn.Linear(num_features, d_model)\n",
        "        self.batch_norm_input = nn.BatchNorm1d(d_model)\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            dim_feedforward=dim_feedforward,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_encoder_layers)\n",
        "\n",
        "        # Output layers with batch normalization\n",
        "        self.batch_norm_output = nn.BatchNorm1d(d_model)\n",
        "        self.percent_change_head = nn.Sequential(\n",
        "            nn.Linear(d_model, d_model // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(d_model // 2, num_classes)\n",
        "        )\n",
        "\n",
        "        self.leg_direction_head = nn.Sequential(\n",
        "            nn.Linear(d_model, d_model // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(d_model // 2, 2)\n",
        "        )\n",
        "\n",
        "        self.price_prediction_head = nn.Sequential(\n",
        "            nn.Linear(d_model, d_model // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(d_model // 2, 1)\n",
        "        )\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src, crypto_id):\n",
        "        src = self.input_linear(src) * math.sqrt(self.d_model)\n",
        "        crypto_emb = self.crypto_embedding(crypto_id).unsqueeze(1)\n",
        "        src = src + crypto_emb\n",
        "\n",
        "        # Apply batch normalization\n",
        "        batch_size, seq_len, feat_dim = src.size()\n",
        "        src = src.view(-1, feat_dim)\n",
        "        src = self.batch_norm_input(src)\n",
        "        src = src.view(batch_size, seq_len, feat_dim)\n",
        "\n",
        "        memory = self.transformer_encoder(src)\n",
        "        features = memory[:, -1, :]\n",
        "\n",
        "        # Apply batch normalization to features\n",
        "        features = self.batch_norm_output(features)\n",
        "        features = self.dropout(features)\n",
        "\n",
        "        percent_change = self.percent_change_head(features)\n",
        "        leg_direction = self.leg_direction_head(features)\n",
        "        price_prediction = self.price_prediction_head(features)\n",
        "\n",
        "        return percent_change, leg_direction, price_prediction\n",
        "\n",
        "class CryptoDataset(Dataset):\n",
        "    def __init__(self, dataframe, feature_cols, window_size=60):\n",
        "        self.data = dataframe\n",
        "        self.feature_cols = feature_cols\n",
        "        self.window_size = window_size\n",
        "        self.cryptos = sorted(dataframe['crypto'].unique())\n",
        "        self.crypto_to_id = {crypto: idx for idx, crypto in enumerate(self.cryptos)}\n",
        "        self.crypto_data = {\n",
        "            crypto: dataframe[dataframe['crypto'] == crypto].sort_values('t').reset_index(drop=True)\n",
        "            for crypto in self.cryptos\n",
        "        }\n",
        "\n",
        "        self.indices = []\n",
        "        for crypto in self.cryptos:\n",
        "            data_length = len(self.crypto_data[crypto])\n",
        "            if data_length > self.window_size:\n",
        "                self.indices.extend([(crypto, idx) for idx in range(data_length - self.window_size)])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        crypto, seq_start = self.indices[idx]\n",
        "        data = self.crypto_data[crypto].iloc[seq_start:seq_start + self.window_size]\n",
        "        features = data[self.feature_cols].values\n",
        "\n",
        "        target_idx = seq_start + self.window_size\n",
        "        data_length = len(self.crypto_data[crypto])\n",
        "        if target_idx >= data_length:\n",
        "            target_idx = data_length - 1\n",
        "\n",
        "        percent_change = self.crypto_data[crypto].iloc[target_idx]['percent_change_classification']\n",
        "        leg_direction = self.crypto_data[crypto].iloc[target_idx]['current_leg_change']\n",
        "        price = self.crypto_data[crypto].iloc[target_idx]['c']\n",
        "\n",
        "        crypto_id = self.crypto_to_id[crypto]\n",
        "\n",
        "        return (\n",
        "            (torch.tensor(features, dtype=torch.float32), torch.tensor(crypto_id, dtype=torch.long)),\n",
        "            (\n",
        "                torch.tensor(percent_change, dtype=torch.long),\n",
        "                torch.tensor(leg_direction, dtype=torch.long),\n",
        "                torch.tensor(price, dtype=torch.float32),\n",
        "            ),\n",
        "        )\n",
        "\n",
        "def train(model, dataloader, criterion_dict, optimizer, scheduler, device):\n",
        "    model.train()\n",
        "    epoch_losses = {\"percent_change\": 0, \"current_leg_change\": 0, \"price\": 0, \"total\": 0}\n",
        "    metrics = {\"percent_change_acc\": 0, \"current_leg_change_acc\": 0, \"price_mse\": 0}\n",
        "    total = 0\n",
        "\n",
        "    for (inputs, crypto_ids), (percent_targets, leg_targets, price_targets) in tqdm(dataloader):\n",
        "        inputs = inputs.to(device)\n",
        "        crypto_ids = crypto_ids.to(device)\n",
        "        percent_targets = percent_targets.to(device)\n",
        "        leg_targets = leg_targets.to(device)\n",
        "        price_targets = price_targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        percent_out, leg_out, price_out = model(inputs, crypto_ids)\n",
        "\n",
        "        loss_percent = criterion_dict['classification'](percent_out, percent_targets)\n",
        "        loss_leg = criterion_dict['classification'](leg_out, leg_targets)\n",
        "        loss_price = criterion_dict['regression'](price_out.squeeze(), price_targets)\n",
        "\n",
        "        # Weighted loss combination\n",
        "        total_loss = 0.4 * loss_percent + 0.4 * loss_leg + 0.2 * loss_price\n",
        "        total_loss.backward()\n",
        "        all_grads = []\n",
        "        for p in model.parameters():\n",
        "            if p.grad is not None:\n",
        "                all_grads.extend(p.grad.cpu().numpy().flatten())\n",
        "\n",
        "\n",
        "\n",
        "        # Gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        batch_size = inputs.size(0)\n",
        "        total += batch_size\n",
        "\n",
        "        # Update losses\n",
        "        epoch_losses[\"percent_change\"] += loss_percent.item() * batch_size\n",
        "        epoch_losses[\"current_leg_change\"] += loss_leg.item() * batch_size\n",
        "        epoch_losses[\"price\"] += loss_price.item() * batch_size\n",
        "        epoch_losses[\"total\"] += total_loss.item() * batch_size\n",
        "\n",
        "        # Update metrics\n",
        "        _, predicted_percent = torch.max(percent_out, 1)\n",
        "        _, predicted_leg = torch.max(leg_out, 1)\n",
        "        metrics[\"percent_change_acc\"] += (predicted_percent == percent_targets).sum().item()\n",
        "        metrics[\"current_leg_change_acc\"] += (predicted_leg == leg_targets).sum().item()\n",
        "        metrics[\"price_mse\"] += loss_price.item() * batch_size\n",
        "    plt.hist(all_grads, bins=50)\n",
        "    plt.title(\"Distribution of Gradients\")\n",
        "    plt.xlabel(\"Gradient Value\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.show()\n",
        "    # Normalize metrics\n",
        "    for key in epoch_losses:\n",
        "        epoch_losses[key] /= total\n",
        "\n",
        "    metrics[\"percent_change_acc\"] /= total\n",
        "    metrics[\"current_leg_change_acc\"] /= total\n",
        "    metrics[\"price_mse\"] /= total\n",
        "\n",
        "    # Update learning rate scheduler\n",
        "    scheduler.step(epoch_losses[\"total\"])\n",
        "\n",
        "    return epoch_losses, metrics\n",
        "\n",
        "def validate(model, dataloader, criterion_dict, device):\n",
        "    model.eval()\n",
        "    val_losses = {\"percent_change\": 0, \"current_leg_change\": 0, \"price\": 0, \"total\": 0}\n",
        "    val_metrics = {\"percent_change_acc\": 0, \"current_leg_change_acc\": 0, \"price_mse\": 0}\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for (inputs, crypto_ids), (percent_targets, leg_targets, price_targets) in dataloader:\n",
        "            inputs = inputs.to(device)\n",
        "            crypto_ids = crypto_ids.to(device)\n",
        "            percent_targets = percent_targets.to(device)\n",
        "            leg_targets = leg_targets.to(device)\n",
        "            price_targets = price_targets.to(device)\n",
        "\n",
        "            percent_out, leg_out, price_out = model(inputs, crypto_ids)\n",
        "\n",
        "            loss_percent = criterion_dict['classification'](percent_out, percent_targets)\n",
        "            loss_leg = criterion_dict['classification'](leg_out, leg_targets)\n",
        "            loss_price = criterion_dict['regression'](price_out.squeeze(), price_targets)\n",
        "            total_loss = 0.4 * loss_percent + 0.4 * loss_leg + 0.2 * loss_price\n",
        "\n",
        "            batch_size = inputs.size(0)\n",
        "            total += batch_size\n",
        "\n",
        "            # Update validation losses and metrics\n",
        "            val_losses[\"percent_change\"] += loss_percent.item() * batch_size\n",
        "            val_losses[\"current_leg_change\"] += loss_leg.item() * batch_size\n",
        "            val_losses[\"price\"] += loss_price.item() * batch_size\n",
        "            val_losses[\"total\"] += total_loss.item() * batch_size\n",
        "\n",
        "            _, predicted_percent = torch.max(percent_out, 1)\n",
        "            _, predicted_leg = torch.max(leg_out, 1)\n",
        "            val_metrics[\"percent_change_acc\"] += (predicted_percent == percent_targets).sum().item()\n",
        "            val_metrics[\"current_leg_change_acc\"] += (predicted_leg == leg_targets).sum().item()\n",
        "            val_metrics[\"price_mse\"] += loss_price.item() * batch_size\n",
        "\n",
        "    # Normalize validation metrics\n",
        "    for key in val_losses:\n",
        "        val_losses[key] /= total\n",
        "\n",
        "    val_metrics[\"percent_change_acc\"] /= total\n",
        "    val_metrics[\"current_leg_change_acc\"] /= total\n",
        "    val_metrics[\"price_mse\"] /= total\n",
        "\n",
        "    return val_losses, val_metrics\n",
        "\n",
        "def main():\n",
        "    # Parameters\n",
        "    batch_size = 64\n",
        "    epochs = 20\n",
        "    learning_rate = 0.001\n",
        "    window_size = 60\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Load and preprocess data\n",
        "    preprocessed_data_dir = 'preprocessed_data'\n",
        "    dfs = []\n",
        "    for ticker in os.listdir(preprocessed_data_dir):\n",
        "        ticker_dir = os.path.join(preprocessed_data_dir, ticker)\n",
        "        if os.path.isdir(ticker_dir):\n",
        "            for file in os.listdir(ticker_dir):\n",
        "                if file.endswith('_preprocessed.csv'):\n",
        "                    filepath = os.path.join(ticker_dir, file)\n",
        "                    df = pd.read_csv(filepath)\n",
        "                    df['crypto'] = ticker\n",
        "                    dfs.append(df)\n",
        "\n",
        "    full_df = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "    target_cols = ['percent_change_classification', 'current_leg_change', 'c']\n",
        "    feature_cols = [col for col in full_df.columns if col not in target_cols + ['t', 'crypto']]\n",
        "\n",
        "    # Normalize features\n",
        "    scaler = StandardScaler()\n",
        "    full_df[feature_cols] = scaler.fit_transform(full_df[feature_cols])\n",
        "\n",
        "    full_df.dropna(subset=feature_cols + target_cols, inplace=True)\n",
        "\n",
        "    # Split data into train, validation, and test sets\n",
        "    train_size = int(0.7 * len(full_df))\n",
        "    val_size = int(0.15 * len(full_df))\n",
        "\n",
        "    train_df = full_df.iloc[:train_size]\n",
        "    val_df = full_df.iloc[train_size:train_size+val_size]\n",
        "    test_df = full_df.iloc[train_size+val_size:]\n",
        "\n",
        "    # Create datasets and dataloaders\n",
        "    train_dataset = CryptoDataset(train_df, feature_cols, window_size)\n",
        "    val_dataset = CryptoDataset(val_df, feature_cols, window_size)\n",
        "    test_dataset = CryptoDataset(test_df, feature_cols, window_size)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Initialize model\n",
        "    num_features = len(feature_cols)\n",
        "    num_cryptos = full_df['crypto'].nunique()\n",
        "    num_classes = full_df['percent_change_classification'].nunique()\n",
        "\n",
        "    model = ShortTermTransformerModel(\n",
        "        num_features=num_features,\n",
        "        num_cryptos=num_cryptos,\n",
        "        d_model=256,\n",
        "        nhead=8,\n",
        "        num_encoder_layers=4,\n",
        "        dim_feedforward=512,\n",
        "        num_classes=num_classes,\n",
        "        max_seq_length=window_size\n",
        "    ).to(device)\n",
        "\n",
        "    criterion_dict = {\n",
        "        'classification': nn.CrossEntropyLoss(),\n",
        "        'regression': nn.MSELoss()\n",
        "    }\n",
        "\n",
        "\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    best_model_state = None\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
        "\n",
        "        # Training phase\n",
        "        train_losses, train_metrics = train(model, train_loader, criterion_dict, optimizer, scheduler, device)\n",
        "        print(f\"Training - Losses: {train_losses}\")\n",
        "        print(f\"Training - Metrics: {train_metrics}\")\n",
        "\n",
        "        # Validation phase\n",
        "        val_losses, val_metrics = validate(model, val_loader, criterion_dict, device)\n",
        "        print(f\"Validation - Losses: {val_losses}\")\n",
        "        print(f\"Validation - Metrics: {val_metrics}\")\n",
        "\n",
        "        # Save best model\n",
        "        if val_losses[\"total\"] < best_val_loss:\n",
        "            best_val_loss = val_losses[\"total\"]\n",
        "            best_model_state = model.state_dict().copy()\n",
        "            print(f\"New best model saved with validation loss: {best_val_loss:.4f}\")\n",
        "\n",
        "    # Save the best model\n",
        "    torch.save(best_model_state, 'best_short_term_transformer_model.pth')\n",
        "    print(\"Best model saved as best_short_term_transformer_model.pth\")\n",
        "\n",
        "    # Final evaluation on test set\n",
        "    model.load_state_dict(best_model_state)\n",
        "    test_losses, test_metrics = validate(model, test_loader, criterion_dict, device)\n",
        "    print(\"\\nFinal Test Results:\")\n",
        "    print(f\"Test Losses: {test_losses}\")\n",
        "    print(f\"Test Metrics: {test_metrics}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "dx5JiLt6CVRo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c9840843-01be-4819-b2db-a8bdac428fd7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1970/1970 [07:39<00:00,  4.29it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA6L0lEQVR4nO3deVwVZf//8fcRBBUBcwFcARW33DXNLTU1NDI1U/PW3O0ul1D0W1ndWlZSuUSLSd0VpN6laS7lbi5ZaplbZrmRCy4sriCUKJz5/eHD8+sIKByPHhhfz8dj/pjrXDPXZ4btzcw151gMwzAEAABgEkVcXQAAAIAzEW4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG6AO+yVV16RxWK5I2O1a9dO7dq1s61v3LhRFotFCxcuvCPjDxo0SEFBQXdkLEelpaVp2LBhCggIkMVi0ZgxY1xdUp4cPXpUFotFsbGxtrY7+b0FFGSEG+AWxMbGymKx2JZixYqpQoUKCg0N1XvvvaeLFy86ZZxTp07plVde0e7du52yP2cqyLXlxZQpUxQbG6tnnnlGc+bM0ZNPPnnD/larVbNnz1anTp1UtmxZFS1aVH5+fnrooYf08ccfKyMj4w5V7hqF/euNu4O7qwsAzGDy5MkKDg7WlStXlJiYqI0bN2rMmDGaMWOGvvnmG9WvX9/W9+WXX9YLL7yQr/2fOnVKr776qoKCgtSwYcM8b7dmzZp8jeOIG9X23//+V1ar9bbXcCvWr1+v+++/X5MmTbpp37///ls9evTQ6tWr1bJlS40fP17+/v46d+6cvv/+e40YMUI///yzPv300ztQeXaOfG/ll6Pfi8CdRLgBnKBLly5q2rSpbX3ChAlav369HnnkET366KPat2+fihcvLklyd3eXu/vt/dH766+/VKJECXl4eNzWcW6maNGiLh0/L5KTk1WnTp089R07dqxWr16tqKgohYeH2702btw4HTp0SGvXrr3hPjIzM2W1Wm/L1+ZOfG8BhQG3pYDb5MEHH9R//vMfHTt2THPnzrW15zQvYu3atWrdurVKlSqlkiVLqmbNmnrxxRclXZ0nc99990mSBg8ebLsFdm2uRbt27VS3bl3t2LFDDzzwgEqUKGHb9vo5N9dkZWXpxRdfVEBAgLy8vPToo4/q+PHjdn2CgoI0aNCgbNv+c583qy2nOTfp6ekaN26cKleuLE9PT9WsWVPTpk2TYRh2/SwWi0aNGqUlS5aobt268vT01L333qtVq1blfMKvk5ycrKFDh8rf31/FihVTgwYN9Pnnn9tevzb/6MiRI1q+fLmt9qNHj+a4v+PHj+uTTz5R586dswWba0JCQjRixAjb+rV5MdOmTVNUVJSqVasmT09P/fHHH7p8+bImTpyoJk2ayNfXV15eXmrTpo02bNiQbb8XLlzQoEGD5Ovrq1KlSmngwIG6cOFCtn65zbmZO3eumjRpouLFi6t06dJ64oknsn29r30f/fHHH2rfvr1KlCihihUr6u2337Y7Zzf6eh86dEg9e/ZUQECAihUrpkqVKumJJ55QSkpKjucLuF2I+MBt9OSTT+rFF1/UmjVrNHz48Bz7/P7773rkkUdUv359TZ48WZ6enoqLi9PmzZslSbVr19bkyZM1ceJEPfXUU2rTpo0kqWXLlrZ9nD17Vl26dNETTzyh/v37y9/f/4Z1vfHGG7JYLHr++eeVnJysqKgodezYUbt377ZdYcqLvNT2T4Zh6NFHH9WGDRs0dOhQNWzYUKtXr9b//d//6eTJk3rnnXfs+v/4449atGiRRowYIW9vb7333nvq2bOn4uPjVaZMmVzr+vvvv9WuXTvFxcVp1KhRCg4O1oIFCzRo0CBduHBB4eHhql27tubMmaOxY8eqUqVKGjdunCSpXLlyOe5z5cqVysrKUv/+/fN8fq6JiYnRpUuX9NRTT8nT01OlS5dWamqqPvnkE/Xt21fDhw/XxYsX9emnnyo0NFTbtm2z3fIxDEPdunXTjz/+qKefflq1a9fW4sWLNXDgwDyN/cYbb+g///mPevfurWHDhun06dN6//339cADD2jXrl0qVaqUre/58+fVuXNnPfbYY+rdu7cWLlyo559/XvXq1VOXLl1u+PW+fPmyQkNDlZGRodGjRysgIEAnT57UsmXLdOHCBfn6+ub7vAEOMwA4LCYmxpBk/PLLL7n28fX1NRo1amRbnzRpkvHPH7133nnHkGScPn0613388ssvhiQjJiYm22tt27Y1JBnR0dE5vta2bVvb+oYNGwxJRsWKFY3U1FRb+1dffWVIMt59911bW2BgoDFw4MCb7vNGtQ0cONAIDAy0rS9ZssSQZLz++ut2/R5//HHDYrEYcXFxtjZJhoeHh13br7/+akgy3n///Wxj/VNUVJQhyZg7d66t7fLly0aLFi2MkiVL2h17YGCgERYWdsP9GYZhjB071pBk7N692649IyPDOH36tG05c+aM7bUjR44YkgwfHx8jOTnZbrvMzEwjIyPDru38+fOGv7+/MWTIEFvbtXP29ttv223bpk2bbOf9+u+to0ePGm5ubsYbb7xhN85vv/1muLu727Vf+z6aPXu23bEFBAQYPXv2tLXl9vXetWuXIclYsGBBtnMH3GnclgJus5IlS97wqalr/zkvXbrU4cm3np6eGjx4cJ77DxgwQN7e3rb1xx9/XOXLl9eKFSscGj+vVqxYITc3Nz377LN27ePGjZNhGFq5cqVde8eOHVWtWjXbev369eXj46PDhw/fdJyAgAD17dvX1la0aFE9++yzSktL0/fff5/v2lNTUyVd/XpeP1a5cuVsS2BgYLZte/bsme2KkJubm23ejdVq1blz55SZmammTZtq586ddvt3d3fXM888Y7ft6NGjb1rzokWLZLVa1bt3b505c8a2BAQEKCQkJNstsJIlS9pdmfLw8FCzZs1uer4l2a7MrF69Wn/99ddN+wO3010dbjZt2qSuXbuqQoUKslgsWrJkSb73YRiGpk2bpho1asjT01MVK1bUG2+84fxiUWilpaXZBYnr9enTR61atdKwYcPk7++vJ554Ql999VW+gk7FihXzNUE1JCTEbt1isah69eq5zjdxlmPHjqlChQrZzkft2rVtr/9TlSpVsu3jnnvu0fnz5286TkhIiIoUsf8Vl9s4eXGt5rS0NLv2Vq1aae3atVq7dq0eeuihHLcNDg7Osf3zzz9X/fr1VaxYMZUpU0blypXT8uXL7eaoHDt2TOXLl88WqmrWrHnTmg8dOiTDMBQSEmIXwMqVK6d9+/YpOTnZrn+lSpWyzdnJy/m+dowRERH65JNPVLZsWYWGhmrmzJnMt4FL3NVzbtLT09WgQQMNGTJEjz32mEP7CA8P15o1azRt2jTVq1dP586d07lz55xcKQqrEydOKCUlRdWrV8+1T/HixbVp0yZt2LBBy5cv16pVqzR//nw9+OCDWrNmjdzc3G46Tn7myeRVbm8Gl5WVlaeanCG3cYzrJh/fCbVq1ZIk7d27Vw0aNLC1lytXTh07dpQku4nj/5TT12fu3LkaNGiQunfvrv/7v/+Tn5+f3NzcFBkZqT///NMpNVutVlksFq1cuTLHc3l9YLrV8z19+nQNGjRIS5cu1Zo1a/Tss88qMjJSP/30kypVqpT/AwAcdFeHmy5duqhLly65vp6RkaGXXnpJX375pS5cuKC6devqrbfesj0psm/fPs2aNUt79+61/ReV239ouDvNmTNHkhQaGnrDfkWKFFGHDh3UoUMHzZgxQ1OmTNFLL72kDRs2qGPHjk5/19lDhw7ZrRuGobi4OLv347nnnntyfCLn2LFjqlq1qm09P7UFBgbqu+++08WLF+2u3uzfv9/2ujMEBgZqz549slqtdldvbmWcLl26yM3NTf/73//Ur1+/W65x4cKFqlq1qhYtWmR3Dq9/v53AwECtW7dOaWlpdmHkwIEDNx2jWrVqMgxDwcHBqlGjxi3XLN38612vXj3Vq1dPL7/8srZs2aJWrVopOjpar7/+ulPGB/Lirr4tdTOjRo3S1q1bNW/ePO3Zs0e9evVS586dbX8Yvv32W1WtWlXLli1TcHCwgoKCNGzYMK7cQNLVN4d77bXXFBwcfMM/hjl9v1x7Uubau916eXlJUo5hwxGzZ8+2mwe0cOFCJSQk2IX9atWq6aefftLly5dtbcuWLcv2CHF+anv44YeVlZWlDz74wK79nXfekcViueE/G/nx8MMPKzExUfPnz7e1ZWZm6v3331fJkiXVtm3bfO+zSpUqGjJkiFauXJmt/mvyc0Xp2lWSf27z888/a+vWrXb9Hn74YWVmZmrWrFm2tqysLL3//vs3HeOxxx6Tm5ubXn311Wy1GYahs2fP5rnea3L7eqempiozM9OurV69eipSpIjp37UZBc9dfeXmRuLj4xUTE6P4+HhVqFBBkjR+/HitWrVKMTExmjJlig4fPqxjx45pwYIFmj17trKysjR27Fg9/vjjWr9+vYuPAHfSypUrtX//fmVmZiopKUnr16/X2rVrFRgYqG+++UbFihXLddvJkydr06ZNCgsLU2BgoJKTk/Xhhx+qUqVKat26taSrQaNUqVKKjo6Wt7e3vLy81Lx5c4evFJYuXVqtW7fW4MGDlZSUpKioKFWvXt3ucfVhw4Zp4cKF6ty5s3r37q0///xTc+fOtZvgm9/aunbtqvbt2+ull17S0aNH1aBBA61Zs0ZLly7VmDFjsu3bUU899ZQ++ugjDRo0SDt27FBQUJAWLlyozZs3Kyoq6oZzoG4kKipKR44c0ejRozVv3jx17dpVfn5+OnPmjDZv3qxvv/02T3NhJOmRRx7RokWL1KNHD4WFhenIkSOKjo5WnTp17Ob1dO3aVa1atdILL7ygo0ePqk6dOlq0aFGe5rJUq1ZNr7/+uiZMmKCjR4+qe/fu8vb21pEjR7R48WI99dRTGj9+fL7OQW5f719//VWjRo1Sr169VKNGDWVmZmrOnDlyc3NTz5498zUGcMtc9JRWgSPJWLx4sW192bJlhiTDy8vLbnF3dzd69+5tGIZhDB8+3JBkHDhwwLbdjh07DEnG/v377/QhwAWuPQp+bfHw8DACAgKMTp06Ge+++67dI8fXXP+47rp164xu3boZFSpUMDw8PIwKFSoYffv2NQ4ePGi33dKlS406deoY7u7udo/itm3b1rj33ntzrC+3R8G//PJLY8KECYafn59RvHhxIywszDh27Fi27adPn25UrFjR8PT0NFq1amVs37492z5vVNv1j4IbhmFcvHjRGDt2rFGhQgWjaNGiRkhIiDF16lTDarXa9ZNkjBw5MltNuT2ifr2kpCRj8ODBRtmyZQ0PDw+jXr16OT6untdHwa/JzMw0YmJijAcffNAoXbq04e7ubpQtW9bo0KGDER0dbfz999+2vtceBZ86dWq2/VitVmPKlClGYGCg4enpaTRq1MhYtmxZjufs7NmzxpNPPmn4+PgYvr6+xpNPPml79PpGj4Jf8/XXXxutW7e2/R6rVauWMXLkSLvfXbl9H+VUT05f78OHDxtDhgwxqlWrZhQrVswoXbq00b59e+O7777L45kFnMdiGC6YmVcAWSwWLV68WN27d5ckzZ8/X/369dPvv/+ebZJdyZIlFRAQoEmTJmnKlCm6cuWK7bW///5bJUqU0Jo1a9SpU6c7eQgAAEDclspVo0aNlJWVpeTkZNu7cF6vVatWyszM1J9//mm7nH7w4EFJzpsYCQAA8ueuvnKTlpamuLg4SVfDzIwZM9S+fXuVLl1aVapUUf/+/bV582ZNnz5djRo10unTp7Vu3TrVr19fYWFhslqtuu+++1SyZElFRUXJarVq5MiR8vHxuSOfxgwAALK7q8PNxo0b1b59+2ztAwcOVGxsrK5cuaLXX39ds2fP1smTJ1W2bFndf//9evXVV1WvXj1J0qlTpzR69GitWbNGXl5e6tKli6ZPn67SpUvf6cMBAAC6y8MNAAAwH97nBgAAmArhBgAAmMpd97SU1WrVqVOn5O3t7fS3tAcAALeHYRi6ePGiKlSokO1Dca9314WbU6dOqXLlyq4uAwAAOOD48eM3/SDWuy7cXHvb9ePHj8vHx8fF1QAAgLxITU1V5cqV8/TxKXdduLl2K8rHx4dwAwBAIZOXKSVMKAYAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKZCuAEAAKbi7uoCAJhf0AvLb9rn6Jthd6ASAHcDrtwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTIdwAAABTcWm4iYyM1H333Sdvb2/5+fmpe/fuOnDgwE23W7BggWrVqqVixYqpXr16WrFixR2oFgAAFAYuDTfff/+9Ro4cqZ9++klr167VlStX9NBDDyk9PT3XbbZs2aK+fftq6NCh2rVrl7p3767u3btr7969d7ByAABQUFkMwzBcXcQ1p0+flp+fn77//ns98MADOfbp06eP0tPTtWzZMlvb/fffr4YNGyo6OvqmY6SmpsrX11cpKSny8fFxWu0Achf0wvKb9jn6ZtgdqARAYZWfv98Fas5NSkqKJKl06dK59tm6das6duxo1xYaGqqtW7fm2D8jI0Opqal2CwAAMK8CE26sVqvGjBmjVq1aqW7durn2S0xMlL+/v12bv7+/EhMTc+wfGRkpX19f21K5cmWn1g0AAAqWAhNuRo4cqb1792revHlO3e+ECROUkpJiW44fP+7U/QMAgILF3dUFSNKoUaO0bNkybdq0SZUqVbph34CAACUlJdm1JSUlKSAgIMf+np6e8vT0dFqtAACgYHPplRvDMDRq1CgtXrxY69evV3Bw8E23adGihdatW2fXtnbtWrVo0eJ2lQkAAAoRl165GTlypL744gstXbpU3t7etnkzvr6+Kl68uCRpwIABqlixoiIjIyVJ4eHhatu2raZPn66wsDDNmzdP27dv18cff+yy4wAAAAWHS6/czJo1SykpKWrXrp3Kly9vW+bPn2/rEx8fr4SEBNt6y5Yt9cUXX+jjjz9WgwYNtHDhQi1ZsuSGk5ABAMDdw6VXbvLyFjsbN27M1tarVy/16tXrNlQEAAAKuwLztBQAAIAzEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpEG4AAICpuDTcbNq0SV27dlWFChVksVi0ZMmSG/bfuHGjLBZLtiUxMfHOFAwAAAo8l4ab9PR0NWjQQDNnzszXdgcOHFBCQoJt8fPzu00VAgCAwsbdlYN36dJFXbp0yfd2fn5+KlWqlPMLAgAAhV6hnHPTsGFDlS9fXp06ddLmzZtv2DcjI0Opqal2CwAAMK9CFW7Kly+v6Ohoff311/r6669VuXJltWvXTjt37sx1m8jISPn6+tqWypUr38GKAQDAnWYxDMNwdRGSZLFYtHjxYnXv3j1f27Vt21ZVqlTRnDlzcnw9IyNDGRkZtvXU1FRVrlxZKSkp8vHxuZWSAeRR0AvLb9rn6Jthd6ASAIVVamqqfH198/T326VzbpyhWbNm+vHHH3N93dPTU56ennewIgAA4EqF6rZUTnbv3q3y5cu7ugwAAFBAuPTKTVpamuLi4mzrR44c0e7du1W6dGlVqVJFEyZM0MmTJzV79mxJUlRUlIKDg3Xvvffq0qVL+uSTT7R+/XqtWbPGVYcAAAAKGJeGm+3bt6t9+/a29YiICEnSwIEDFRsbq4SEBMXHx9tev3z5ssaNG6eTJ0+qRIkSql+/vr777ju7fQAAgLtbgZlQfKfkZ0ISAOdgQjGAW5Wfv9+Ffs4NAADAPxFuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqRBuAACAqTgUbg4fPuzsOgAAAJzCoXBTvXp1tW/fXnPnztWlS5ecXRMAAIDDHAo3O3fuVP369RUREaGAgAD9+9//1rZt25xdGwAAQL45FG4aNmyod999V6dOndJnn32mhIQEtW7dWnXr1tWMGTN0+vRpZ9cJAACQJ7c0odjd3V2PPfaYFixYoLfeektxcXEaP368KleurAEDBighIcFZdQIAAOTJLYWb7du3a8SIESpfvrxmzJih8ePH688//9TatWt16tQpdevWzVl1AgAA5Im7IxvNmDFDMTExOnDggB5++GHNnj1bDz/8sIoUuZqVgoODFRsbq6CgIGfWCgAAcFMOhZtZs2ZpyJAhGjRokMqXL59jHz8/P3366ae3VBwAAEB+ORRuDh06dNM+Hh4eGjhwoCO7BwAAcJhDc25iYmK0YMGCbO0LFizQ559/fstFAQAAOMqhcBMZGamyZctma/fz89OUKVNuuSgAAABHORRu4uPjFRwcnK09MDBQ8fHxt1wUAACAoxwKN35+ftqzZ0+29l9//VVlypS55aIAAAAc5VC46du3r5599llt2LBBWVlZysrK0vr16xUeHq4nnnjC2TUCAADkmUNPS7322ms6evSoOnToIHf3q7uwWq0aMGAAc24AAIBLORRuPDw8NH/+fL322mv69ddfVbx4cdWrV0+BgYHOrg8AACBfHAo319SoUUM1atRwVi0AAAC3zKFwk5WVpdjYWK1bt07JycmyWq12r69fv94pxQEAAOSXQ+EmPDxcsbGxCgsLU926dWWxWJxdFwAAgEMcCjfz5s3TV199pYcfftjZ9QAAANwShx4F9/DwUPXq1Z1dCwAAwC1zKNyMGzdO7777rgzDcHY9AAAAt8Sh21I//vijNmzYoJUrV+ree+9V0aJF7V5ftGiRU4oDAADIL4fCTalSpdSjRw9n1wIAAHDLHAo3MTExzq4DAADAKRyacyNJmZmZ+u677/TRRx/p4sWLkqRTp04pLS3NacUBAADkl0NXbo4dO6bOnTsrPj5eGRkZ6tSpk7y9vfXWW28pIyND0dHRzq4TAAAgTxy6chMeHq6mTZvq/PnzKl68uK29R48eWrdundOKAwAAyC+Hrtz88MMP2rJlizw8POzag4KCdPLkSacUBgAA4AiHrtxYrVZlZWVlaz9x4oS8vb1vuSgAAABHORRuHnroIUVFRdnWLRaL0tLSNGnSJD6SAQAAuJRDt6WmT5+u0NBQ1alTR5cuXdK//vUvHTp0SGXLltWXX37p7BoBAADyzKFwU6lSJf3666+aN2+e9uzZo7S0NA0dOlT9+vWzm2AMAABwpzkUbiTJ3d1d/fv3d2YtAAAAt8yhcDN79uwbvj5gwACHigEAALhVDoWb8PBwu/UrV67or7/+koeHh0qUKEG4AQAALuPQ01Lnz5+3W9LS0nTgwAG1bt2aCcUAAMClHP5sqeuFhITozTffzHZVBwAA4E5yWriRrk4yPnXqlDN3CQAAkC8Ozbn55ptv7NYNw1BCQoI++OADtWrVyimFAQAAOMKhcNO9e3e7dYvFonLlyunBBx/U9OnTnVEXAACAQxwKN1ar1dl1AAAAOIVT59wAAAC4mkNXbiIiIvLcd8aMGY4MAQAA4BCHws2uXbu0a9cuXblyRTVr1pQkHTx4UG5ubmrcuLGtn8VicU6VAAAAeeRQuOnatau8vb31+eef65577pF09Y39Bg8erDZt2mjcuHFOLRIAACCvHJpzM336dEVGRtqCjSTdc889ev3113laCgAAuJRD4SY1NVWnT5/O1n769GldvHjxlosCAABwlEPhpkePHho8eLAWLVqkEydO6MSJE/r66681dOhQPfbYY86uEQAAIM8cmnMTHR2t8ePH61//+peuXLlydUfu7ho6dKimTp3q1AIBAADyw6ErNyVKlNCHH36os2fP2p6cOnfunD788EN5eXnleT+bNm1S165dVaFCBVksFi1ZsuSm22zcuFGNGzeWp6enqlevrtjYWEcOAQAAmNQtvYlfQkKCEhISFBISIi8vLxmGka/t09PT1aBBA82cOTNP/Y8cOaKwsDC1b99eu3fv1pgxYzRs2DCtXr3akfIBAIAJOXRb6uzZs+rdu7c2bNggi8WiQ4cOqWrVqho6dKjuueeePD8x1aVLF3Xp0iXP40ZHRys4ONi2/9q1a+vHH3/UO++8o9DQUEcOBQAAmIxDV27Gjh2rokWLKj4+XiVKlLC19+nTR6tWrXJacdfbunWrOnbsaNcWGhqqrVu35rpNRkaGUlNT7RYAAGBeDoWbNWvW6K233lKlSpXs2kNCQnTs2DGnFJaTxMRE+fv727X5+/srNTVVf//9d47bREZGytfX17ZUrlz5ttUHAABcz6Fwk56ebnfF5ppz587J09PzlotypgkTJiglJcW2HD9+3NUlAQCA28ihcNOmTRvNnj3btm6xWGS1WvX222+rffv2TivuegEBAUpKSrJrS0pKko+Pj4oXL57jNp6envLx8bFbAACAeTk0ofjtt99Whw4dtH37dl2+fFnPPfecfv/9d507d06bN292do02LVq00IoVK+za1q5dqxYtWty2MQEAQOHi0JWbunXr6uDBg2rdurW6deum9PR0PfbYY9q1a5eqVauW5/2kpaVp9+7d2r17t6Srj3rv3r1b8fHxkq7eUhowYICt/9NPP63Dhw/rueee0/79+/Xhhx/qq6++0tixYx05DAAAYEL5vnJz5coVde7cWdHR0XrppZduafDt27fb3caKiIiQJA0cOFCxsbFKSEiwBR1JCg4O1vLlyzV27Fi9++67qlSpkj755BMeAwcAADb5DjdFixbVnj17nDJ4u3btbvjGfzm9+3C7du20a9cup4wPAADMx6HbUv3799enn37q7FoAAABumUMTijMzM/XZZ5/pu+++U5MmTbJ9ntSMGTOcUhwAAEB+5SvcHD58WEFBQdq7d68aN24sSTp48KBdH4vF4rzqAAAA8ilf4SYkJEQJCQnasGGDpKsft/Dee+9le9dgAAAAV8nXnJvrJ/+uXLlS6enpTi0IAADgVjg0ofiaGz3pBAAA4Ar5CjcWiyXbnBrm2AAAgIIkX3NuDMPQoEGDbB+OeenSJT399NPZnpZatGiR8yoEAADIh3yFm4EDB9qt9+/f36nFAAAA3Kp8hZuYmJjbVQcAAIBT3NKEYgAAgIKGcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEyFcAMAAEylQISbmTNnKigoSMWKFVPz5s21bdu2XPvGxsbKYrHYLcWKFbuD1QIAgILM5eFm/vz5ioiI0KRJk7Rz5041aNBAoaGhSk5OznUbHx8fJSQk2JZjx47dwYoBAEBB5vJwM2PGDA0fPlyDBw9WnTp1FB0drRIlSuizzz7LdRuLxaKAgADb4u/vfwcrBgAABZlLw83ly5e1Y8cOdezY0dZWpEgRdezYUVu3bs11u7S0NAUGBqpy5crq1q2bfv/991z7ZmRkKDU11W4BAADm5dJwc+bMGWVlZWW78uLv76/ExMQct6lZs6Y+++wzLV26VHPnzpXValXLli114sSJHPtHRkbK19fXtlSuXNnpxwEAAAoOl9+Wyq8WLVpowIABatiwodq2batFixapXLly+uijj3LsP2HCBKWkpNiW48eP3+GKAQDAneTuysHLli0rNzc3JSUl2bUnJSUpICAgT/soWrSoGjVqpLi4uBxf9/T0lKen5y3XCgAACgeXXrnx8PBQkyZNtG7dOlub1WrVunXr1KJFizztIysrS7/99pvKly9/u8oEAACFiEuv3EhSRESEBg4cqKZNm6pZs2aKiopSenq6Bg8eLEkaMGCAKlasqMjISEnS5MmTdf/996t69eq6cOGCpk6dqmPHjmnYsGGuPAwAAFBAuDzc9OnTR6dPn9bEiROVmJiohg0batWqVbZJxvHx8SpS5P9fYDp//ryGDx+uxMRE3XPPPWrSpIm2bNmiOnXquOoQAABAAWIxDMNwdRF3Umpqqnx9fZWSkiIfHx9XlwPcFYJeWH7TPkffDLsDlQAorPLz97vQPS0FAABwI4QbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKoQbAABgKu6uLgAAJCnoheU37XP0zbA7UAmAwo4rNwAAwFQKRLiZOXOmgoKCVKxYMTVv3lzbtm27Yf8FCxaoVq1aKlasmOrVq6cVK1bcoUoBAEBB5/JwM3/+fEVERGjSpEnauXOnGjRooNDQUCUnJ+fYf8uWLerbt6+GDh2qXbt2qXv37urevbv27t17hysHAAAFkcUwDMOVBTRv3lz33XefPvjgA0mS1WpV5cqVNXr0aL3wwgvZ+vfp00fp6elatmyZre3+++9Xw4YNFR0dfdPxUlNT5evrq5SUFPn4+DjvQIC7VF7myjgLc26Au1d+/n679MrN5cuXtWPHDnXs2NHWVqRIEXXs2FFbt27NcZutW7fa9Zek0NDQXPsDAIC7i0ufljpz5oyysrLk7+9v1+7v76/9+/fnuE1iYmKO/RMTE3Psn5GRoYyMDNt6SkqKpKsJEMCN1Z202tUl2KkydsFN++x9NfQOVALgTrv2dzsvN5xM/yh4ZGSkXn311WztlStXdkE1AG433yhXVwDgdrp48aJ8fX1v2Mel4aZs2bJyc3NTUlKSXXtSUpICAgJy3CYgICBf/SdMmKCIiAjbutVq1blz51SmTBlZLJZbPIKCJTU1VZUrV9bx48eZT+REnNfbg/N6e3BenY9zenvk97wahqGLFy+qQoUKN+3r0nDj4eGhJk2aaN26derevbukq+Fj3bp1GjVqVI7btGjRQuvWrdOYMWNsbWvXrlWLFi1y7O/p6SlPT0+7tlKlSjmj/ALLx8eHH8DbgPN6e3Bebw/Oq/NxTm+P/JzXm12xucblt6UiIiI0cOBANW3aVM2aNVNUVJTS09M1ePBgSdKAAQNUsWJFRUZGSpLCw8PVtm1bTZ8+XWFhYZo3b562b9+ujz/+2JWHAQAACgiXh5s+ffro9OnTmjhxohITE9WwYUOtWrXKNmk4Pj5eRYr8/4e6WrZsqS+++EIvv/yyXnzxRYWEhGjJkiWqW7euqw4BAAAUIC4PN5I0atSoXG9Dbdy4MVtbr1691KtXr9tcVeHj6empSZMmZbsNh1vDeb09OK+3B+fV+Tint8ftPK8ufxM/AAAAZ3L5xy8AAAA4E+EGAACYCuEGAACYCuEGAACYCuHmLpCRkaGGDRvKYrFo9+7dri6n0Dp69KiGDh2q4OBgFS9eXNWqVdOkSZN0+fJlV5dW6MycOVNBQUEqVqyYmjdvrm3btrm6pEItMjJS9913n7y9veXn56fu3bvrwIEDri7LdN58801ZLBa7N5GFY06ePKn+/furTJkyKl68uOrVq6ft27c7bf+Em7vAc889l6e3q8aN7d+/X1arVR999JF+//13vfPOO4qOjtaLL77o6tIKlfnz5ysiIkKTJk3Szp071aBBA4WGhio5OdnVpRVa33//vUaOHKmffvpJa9eu1ZUrV/TQQw8pPT3d1aWZxi+//KKPPvpI9evXd3Uphd758+fVqlUrFS1aVCtXrtQff/yh6dOn65577nHeIAZMbcWKFUatWrWM33//3ZBk7Nq1y9Ulmcrbb79tBAcHu7qMQqVZs2bGyJEjbetZWVlGhQoVjMjISBdWZS7JycmGJOP77793dSmmcPHiRSMkJMRYu3at0bZtWyM8PNzVJRVqzz//vNG6devbOgZXbkwsKSlJw4cP15w5c1SiRAlXl2NKKSkpKl26tKvLKDQuX76sHTt2qGPHjra2IkWKqGPHjtq6dasLKzOXlJQUSeJ700lGjhypsLAwu+9bOO6bb75R06ZN1atXL/n5+alRo0b673//69QxCDcmZRiGBg0apKefflpNmzZ1dTmmFBcXp/fff1///ve/XV1KoXHmzBllZWXZPl7lGn9/fyUmJrqoKnOxWq0aM2aMWrVqxcfSOMG8efO0c+dO2+cb4tYdPnxYs2bNUkhIiFavXq1nnnlGzz77rD7//HOnjUG4KWReeOEFWSyWGy779+/X+++/r4sXL2rChAmuLrnAy+s5/aeTJ0+qc+fO6tWrl4YPH+6iyoHsRo4cqb1792revHmuLqXQO378uMLDw/W///1PxYoVc3U5pmG1WtW4cWNNmTJFjRo10lNPPaXhw4crOjraaWMUiM+WQt6NGzdOgwYNumGfqlWrav369dq6dWu2z+xo2rSp+vXr59SEXNjl9Zxec+rUKbVv314tW7bk0+jzqWzZsnJzc1NSUpJde1JSkgICAlxUlXmMGjVKy5Yt06ZNm1SpUiVXl1Po7dixQ8nJyWrcuLGtLSsrS5s2bdIHH3ygjIwMubm5ubDCwql8+fKqU6eOXVvt2rX19ddfO20Mwk0hU65cOZUrV+6m/d577z29/vrrtvVTp04pNDRU8+fPV/PmzW9niYVOXs+pdPWKTfv27dWkSRPFxMTYfWI9bs7Dw0NNmjTRunXr1L17d0lX/4tbt25drh+ei5szDEOjR4/W4sWLtXHjRgUHB7u6JFPo0KGDfvvtN7u2wYMHq1atWnr++ecJNg5q1apVtrcqOHjwoAIDA502BuHGpKpUqWK3XrJkSUlStWrV+I/OQSdPnlS7du0UGBioadOm6fTp07bXuOqQdxERERo4cKCaNm2qZs2aKSoqSunp6Ro8eLCrSyu0Ro4cqS+++EJLly6Vt7e3bf6Sr6+vihcv7uLqCi9vb+9s85a8vLxUpkwZ5jPdgrFjx6ply5aaMmWKevfurW3btunjjz926pVwwg2QR2vXrlVcXJzi4uKyBUTDMFxUVeHTp08fnT59WhMnTlRiYqIaNmyoVatWZZtkjLybNWuWJKldu3Z27TExMTe95Qrcaffdd58WL16sCRMmaPLkyQoODlZUVJT69evntDEsBr+VAQCAiTBhAAAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBgAAmArhBoBLDRo0yPZRDNLVN6IbM2aMy+q5VYW9fuBWbNq0SV27dlWFChVksVi0ZMmSfO/DMAxNmzZNNWrUkKenpypWrKg33ngjX/sg3ACwSUxMVHh4uKpXr65ixYrJ399frVq10qxZs/TXX3/dkRoWLVqk1157zan7vD5A5aRr167q3Llzjq/98MMPslgs2rNnj1PrAswmPT1dDRo00MyZMx3eR3h4uD755BNNmzZN+/fv1zfffKNmzZrlax98/AIASdLhw4fVqlUrlSpVSlOmTFG9evXk6emp3377TR9//LEqVqyoRx99NMdtr1y5oqJFizqljtKlSztlP/k1dOhQ9ezZUydOnMj28RoxMTFq2rSp6tev75LagMKiS5cu6tKlS66vZ2Rk6KWXXtKXX36pCxcuqG7dunrrrbdsHx2yb98+zZo1S3v37lXNmjUlyaEPguXKDQBJ0ogRI+Tu7q7t27erd+/eql27tqpWrapu3bpp+fLl6tq1q62vxWLRrFmz9Oijj8rLy0tvvPGGsrKyNHToUAUHB6t48eKqWbOm3n33XbsxsrKyFBERoVKlSqlMmTJ67rnnsn0u1/W3dTIyMjR+/HhVrFhRXl5eat68uTZu3Gh7PTY2VqVKldLq1atVu3ZtlSxZUp07d1ZCQoIk6ZVXXtHnn3+upUuXymKxyGKx2G1/zSOPPKJy5copNjbWrj0tLU0LFizQ0KFDdfbsWfXt21cVK1ZUiRIlVK9ePX355Zc3PK85XZovVaqU3TjHjx9X7969VapUKZUuXVrdunXT0aNHb7hfoDAaNWqUtm7dqnnz5mnPnj3q1auXOnfurEOHDkmSvv32W1WtWlXLli1TcHCwgoKCNGzYMJ07dy5f4xBuAOjs2bNas2aNRo4cKS8vrxz7WCwWu/VXXnlFPXr00G+//aYhQ4bIarWqUqVKWrBggf744w9NnDhRL774or766ivbNtOnT1dsbKw+++wz/fjjjzp37pwWL158w9pu9stQkv766y9NmzZNc+bM0aZNmxQfH6/x48dLksaPH6/evXvbAk9CQoJatmyZbRx3d3cNGDBAsbGxdoFrwYIFysrKUt++fXXp0iU1adJEy5cv1969e/XUU0/pySef1LZt225+knNx5coVhYaGytvbWz/88IM2b95sC2iXL192eL9AQRMfH6+YmBgtWLBAbdq0UbVq1TR+/Hi1bt1aMTExkq5eQT527JgWLFig2bNnKzY2Vjt27NDjjz+ev8EMAHe9n376yZBkLFq0yK69TJkyhpeXl+Hl5WU899xztnZJxpgxY26635EjRxo9e/a0rZcvX954++23betXrlwxKlWqZHTr1s3W1rZtWyM8PNwwDMM4duyY4ebmZpw8edJuvx06dDAmTJhgGIZhxMTEGJKMuLg42+szZ840/P39besDBw60GyM3+/btMyQZGzZssLW1adPG6N+/f67bhIWFGePGjcuxfsO4eq4WL15st42vr68RExNjGIZhzJkzx6hZs6ZhtVptr2dkZBjFixc3Vq9efdOagYLq+u/9ZcuWGZJsv1OuLe7u7kbv3r0NwzCM4cOHG5KMAwcO2LbbsWOHIcnYv39/nsdmzg2AXG3btk1Wq1X9+vVTRkaG3WtNmzbN1n/mzJn67LPPFB8fr7///luXL19Ww4YNJUkpKSlKSEhQ8+bNbf3d3d3VtGnTbLemrvntt9+UlZWlGjVq2LVnZGSoTJkytvUSJUqoWrVqtvXy5csrOTk538dbq1YttWzZUp999pnatWunuLg4/fDDD5o8ebKkq7fVpkyZoq+++konT57U5cuXlZGRoRIlSuR7rGt+/fVXxcXFydvb26790qVL+vPPPx3eL1DQpKWlyc3NTTt27JCbm5vdayVLlpR09WfX3d3d7me+du3akq5e+bk2D+dmCDcAVL16dVksFh04cMCuvWrVqpKk4sWLZ9vm+ttX8+bN0/jx4zV9+nS1aNFC3t7emjp1qn7++WeH68rLL0NJ2SYzWyyWXAPTzQwdOlSjR4/WzJkzFRMTo2rVqqlt27aSpKlTp+rdd99VVFSU6tWrJy8vL40ZM+aGt49yquXKlSt2x9ikSRP973//y7ZtuXLlHDoGoCBq1KiRsrKylJycrDZt2uTYp1WrVsrMzNSff/5p+4fl4MGDkqTAwMA8j0W4AaAyZcqoU6dO+uCDDzR69Ohc593cyObNm9WyZUuNGDHC1vbPKw++vr4qX768fv75Zz3wwAOSpMzMTO3YsUONGzfOcZ95+WWYFx4eHsrKyspT3969eys8PFxffPGFZs+erWeeecY232jz5s3q1q2b+vfvL0myWq06ePCg6tSpk+v+ypUrZ5vcLEmHDh2ye6y+cePGmj9/vvz8/OTj4+PI4QEFRlpamuLi4mzrR44c0e7du1W6dGnVqFFD/fr104ABAzR9+nQ1atRIp0+f1rp161S/fn2FhYWpY8eOaty4sYYMGaKoqChZrVaNHDlSnTp1ynYF90aYUAxAkvThhx8qMzNTTZs21fz587Vv3z4dOHBAc+fO1f79+7NdObleSEiItm/frtWrV+vgwYP6z3/+o19++cWuT3h4uN58800tWbJE+/fv14gRI3ThwoVc9/nPX4aLFi3SkSNHtG3bNkVGRmr58uV5PragoCDt2bNHBw4c0JkzZ+yunFyvZMmS6tOnjyZMmKCEhAQNGjTI7hjXrl2rLVu2aN++ffr3v/+tpKSkG4794IMP6oMPPtCuXbu0fft2Pf3003ZXmvr166eyZcuqW7du+uGHH3TkyBFt3LhRzz77rE6cOJHnYwQKgu3bt6tRo0Zq1KiRJCkiIkKNGjXSxIkTJV19W4UBAwZo3Lhxqlmzprp3765ffvlFVapUkSQVKVJE3377rcqWLasHHnhAYWFhql27tubNm5e/QpwzbQiAGZw6dcoYNWqUERwcbBQtWtQoWbKk0axZM2Pq1KlGenq6rZ9ymCR76dIlY9CgQYavr69RqlQp45lnnjFeeOEFo0GDBrY+V65cMcLDww0fHx+jVKlSRkREhDFgwIBcJxQbhmFcvnzZmDhxohEUFGQULVrUKF++vNGjRw9jz549hmFcnVDs6+trV8vixYuNf/56S05ONjp16mSULFky24ThnGzZssWQZDz88MN27WfPnjW6detmlCxZ0vDz8zNefvnlm9Z/8uRJ46GHHjK8vLyMkJAQY8WKFXYTig3DMBISEowBAwYYZcuWNTw9PY2qVasaw4cPN1JSUm5YJ4CcWQzDwRvTAAAABRC3pQAAgKkQbgAAgKkQbgAAgKkQbgAAgKkQbgAAgKkQbgAAgKkQbgAAgKkQbgAAgKkQbgAAgKkQbgAAgKkQbgAAgKkQbgAAgKn8P+9/0XGyuiOMAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training - Losses: {'percent_change': 1.8835173225721704, 'current_leg_change': 0.1429860368390606, 'price': 501671257.3825053, 'total': 100334253.62091368}\n",
            "Training - Metrics: {'percent_change_acc': 0.19539746630599472, 'current_leg_change_acc': 0.9995716359540222, 'price_mse': 501671257.3825053}\n",
            "Validation - Losses: {'percent_change': 1.8477371843737567, 'current_leg_change': 0.206960565583193, 'price': 748.9179059939041, 'total': 150.60546259627645}\n",
            "Validation - Metrics: {'percent_change_acc': 0.19983677708943873, 'current_leg_change_acc': 1.0, 'price_mse': 748.9179059939041}\n",
            "New best model saved with validation loss: 150.6055\n",
            "\n",
            "Epoch 2/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1970/1970 [07:44<00:00,  4.25it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training - Losses: {'percent_change': 1.8791217012107555, 'current_leg_change': 0.030250690668517335, 'price': 41905428.28962962, 'total': 8381086.570338963}\n",
            "Training - Metrics: {'percent_change_acc': 0.19446141153885818, 'current_leg_change_acc': 1.0, 'price_mse': 41905428.28962962}\n",
            "Validation - Losses: {'percent_change': 1.829079311856372, 'current_leg_change': 0.0008294250633673704, 'price': 781.9381578920166, 'total': 157.11959826793694}\n",
            "Validation - Metrics: {'percent_change_acc': 0.20106094891864823, 'current_leg_change_acc': 1.0, 'price_mse': 781.9381578920166}\n",
            "\n",
            "Epoch 3/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 34%|███▎      | 661/1970 [02:48<05:33,  3.92it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-3f37138ef991>\u001b[0m in \u001b[0;36m<cell line: 351>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-20-3f37138ef991>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;31m# Training phase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training - Losses: {train_losses}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training - Metrics: {train_metrics}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-3f37138ef991>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, criterion_dict, optimizer, scheduler, device)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrypto_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpercent_targets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleg_targets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprice_targets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mcrypto_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrypto_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-3f37138ef991>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mcrypto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrypto_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcrypto\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseq_start\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mseq_start\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mtarget_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq_start\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4107\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4108\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4110\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6194\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_as_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6195\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6196\u001b[0m             \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6197\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_indexer_for\u001b[0;34m(self, target)\u001b[0m\n\u001b[1;32m   6180\u001b[0m         \"\"\"\n\u001b[1;32m   6181\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_as_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6182\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6183\u001b[0m         \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6184\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_indexer\u001b[0;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[1;32m   3878\u001b[0m         \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_reindex_fill_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3879\u001b[0m         \u001b[0morig_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3880\u001b[0;31m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3882\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_indexing_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_maybe_cast_listlike_indexer\u001b[0;34m(self, target)\u001b[0m\n\u001b[1;32m   6681\u001b[0m         \u001b[0mAnalogue\u001b[0m \u001b[0mto\u001b[0m \u001b[0mmaybe_cast_indexer\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mget_indexer\u001b[0m \u001b[0minstead\u001b[0m \u001b[0mof\u001b[0m \u001b[0mget_loc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6682\u001b[0m         \"\"\"\n\u001b[0;32m-> 6683\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6685\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mensure_index\u001b[0;34m(index_like, copy)\u001b[0m\n\u001b[1;32m   7647\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtupleize_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7648\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7649\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, data, dtype, copy, name, tupleize_cols)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_simple_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrefs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_pandas_object\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdata_dtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdata_dtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_simple_new\u001b[0;34m(cls, values, name, refs)\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0mMust\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mcareful\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mto\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m         \"\"\"\n\u001b[0;32m--> 659\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#batch to layer\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "class ShortTermTransformerModel(nn.Module):\n",
        "    def __init__(self, num_features, num_cryptos, d_model=256, nhead=8, num_encoder_layers=4,\n",
        "                 dim_feedforward=512, dropout=0.3, num_classes=3, max_seq_length=50):\n",
        "        super(ShortTermTransformerModel, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.crypto_embedding = nn.Embedding(num_cryptos, d_model)\n",
        "        self.input_linear = nn.Linear(num_features, d_model)\n",
        "        self.batch_norm_input = nn.BatchNorm1d(d_model)\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            dim_feedforward=dim_feedforward,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_encoder_layers)\n",
        "\n",
        "        # Define Layer Normalization layers\n",
        "        self.input_layer_norm = nn.LayerNorm(d_model)\n",
        "        self.output_layer_norm = nn.LayerNorm(d_model)  # Add this layer\n",
        "\n",
        "        self.percent_change_head = nn.Sequential(\n",
        "            nn.Linear(d_model, d_model // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(d_model // 2, num_classes)\n",
        "        )\n",
        "\n",
        "        self.leg_direction_head = nn.Sequential(\n",
        "            nn.Linear(d_model, d_model // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(d_model // 2, 2)\n",
        "        )\n",
        "\n",
        "        self.price_prediction_head = nn.Sequential(\n",
        "            nn.Linear(d_model, d_model // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(d_model // 2, 1)\n",
        "        )\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src, crypto_id):\n",
        "        src = self.input_linear(src) * math.sqrt(self.d_model)\n",
        "        crypto_emb = self.crypto_embedding(crypto_id).unsqueeze(1)\n",
        "        src = src + crypto_emb\n",
        "\n",
        "        # Apply Layer Normalization to input\n",
        "        src = self.input_layer_norm(src)\n",
        "\n",
        "        memory = self.transformer_encoder(src)\n",
        "        features = memory[:, -1, :]\n",
        "\n",
        "        # Apply Layer Normalization to features\n",
        "        features = self.output_layer_norm(features)  # Normalize before feeding to heads\n",
        "        features = self.dropout(features)\n",
        "\n",
        "        percent_change = self.percent_change_head(features)\n",
        "        leg_direction = self.leg_direction_head(features)\n",
        "        price_prediction = self.price_prediction_head(features)\n",
        "\n",
        "        return percent_change, leg_direction, price_prediction\n",
        "\n",
        "\n",
        "\n",
        "class CryptoDataset(Dataset):\n",
        "    def __init__(self, dataframe, feature_cols, window_size=60):\n",
        "        self.data = dataframe\n",
        "        self.feature_cols = feature_cols\n",
        "        self.window_size = window_size\n",
        "        self.cryptos = sorted(dataframe['crypto'].unique())\n",
        "        self.crypto_to_id = {crypto: idx for idx, crypto in enumerate(self.cryptos)}\n",
        "        self.crypto_data = {\n",
        "            crypto: dataframe[dataframe['crypto'] == crypto].sort_values('t').reset_index(drop=True)\n",
        "            for crypto in self.cryptos\n",
        "        }\n",
        "\n",
        "        self.indices = []\n",
        "        for crypto in self.cryptos:\n",
        "            data_length = len(self.crypto_data[crypto])\n",
        "            if data_length > self.window_size:\n",
        "                self.indices.extend([(crypto, idx) for idx in range(data_length - self.window_size)])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        crypto, seq_start = self.indices[idx]\n",
        "        data = self.crypto_data[crypto].iloc[seq_start:seq_start + self.window_size]\n",
        "        features = data[self.feature_cols].values\n",
        "\n",
        "        target_idx = seq_start + self.window_size\n",
        "        data_length = len(self.crypto_data[crypto])\n",
        "        if target_idx >= data_length:\n",
        "            target_idx = data_length - 1\n",
        "\n",
        "        percent_change = self.crypto_data[crypto].iloc[target_idx]['percent_change_classification']\n",
        "        leg_direction = self.crypto_data[crypto].iloc[target_idx]['current_leg_change']\n",
        "        price = self.crypto_data[crypto].iloc[target_idx]['c']\n",
        "\n",
        "        crypto_id = self.crypto_to_id[crypto]\n",
        "\n",
        "        return (\n",
        "            (torch.tensor(features, dtype=torch.float32), torch.tensor(crypto_id, dtype=torch.long)),\n",
        "            (\n",
        "                torch.tensor(percent_change, dtype=torch.long),\n",
        "                torch.tensor(leg_direction, dtype=torch.long),\n",
        "                torch.tensor(price, dtype=torch.float32),\n",
        "            ),\n",
        "        )\n",
        "\n",
        "def train(model, dataloader, criterion_dict, optimizer, scheduler, device):\n",
        "    model.train()\n",
        "    epoch_losses = {\"percent_change\": 0, \"current_leg_change\": 0, \"price\": 0, \"total\": 0}\n",
        "    metrics = {\"percent_change_acc\": 0, \"current_leg_change_acc\": 0, \"price_mse\": 0}\n",
        "    total = 0\n",
        "\n",
        "    for (inputs, crypto_ids), (percent_targets, leg_targets, price_targets) in tqdm(dataloader):\n",
        "        inputs = inputs.to(device)\n",
        "        crypto_ids = crypto_ids.to(device)\n",
        "        percent_targets = percent_targets.to(device)\n",
        "        leg_targets = leg_targets.to(device)\n",
        "        price_targets = price_targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        percent_out, leg_out, price_out = model(inputs, crypto_ids)\n",
        "\n",
        "        loss_percent = criterion_dict['classification'](percent_out, percent_targets)\n",
        "        loss_leg = criterion_dict['classification'](leg_out, leg_targets)\n",
        "        loss_price = criterion_dict['regression'](price_out.squeeze(), price_targets)\n",
        "\n",
        "        # Weighted loss combination\n",
        "        total_loss = 0.4 * loss_percent + 0.4 * loss_leg + 0.2 * loss_price\n",
        "        total_loss.backward()\n",
        "        all_grads = []\n",
        "        for p in model.parameters():\n",
        "            if p.grad is not None:\n",
        "                all_grads.extend(p.grad.cpu().numpy().flatten())\n",
        "\n",
        "\n",
        "\n",
        "        # Gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        batch_size = inputs.size(0)\n",
        "        total += batch_size\n",
        "\n",
        "        # Update losses\n",
        "        epoch_losses[\"percent_change\"] += loss_percent.item() * batch_size\n",
        "        epoch_losses[\"current_leg_change\"] += loss_leg.item() * batch_size\n",
        "        epoch_losses[\"price\"] += loss_price.item() * batch_size\n",
        "        epoch_losses[\"total\"] += total_loss.item() * batch_size\n",
        "\n",
        "        # Update metrics\n",
        "        _, predicted_percent = torch.max(percent_out, 1)\n",
        "        _, predicted_leg = torch.max(leg_out, 1)\n",
        "        metrics[\"percent_change_acc\"] += (predicted_percent == percent_targets).sum().item()\n",
        "        metrics[\"current_leg_change_acc\"] += (predicted_leg == leg_targets).sum().item()\n",
        "        metrics[\"price_mse\"] += loss_price.item() * batch_size\n",
        "    plt.hist(all_grads, bins=50)\n",
        "    plt.title(\"Distribution of Gradients\")\n",
        "    plt.xlabel(\"Gradient Value\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.show()\n",
        "    # Normalize metrics\n",
        "    for key in epoch_losses:\n",
        "        epoch_losses[key] /= total\n",
        "\n",
        "    metrics[\"percent_change_acc\"] /= total\n",
        "    metrics[\"current_leg_change_acc\"] /= total\n",
        "    metrics[\"price_mse\"] /= total\n",
        "\n",
        "    # Update learning rate scheduler\n",
        "    scheduler.step(epoch_losses[\"total\"])\n",
        "\n",
        "    return epoch_losses, metrics\n",
        "\n",
        "def validate(model, dataloader, criterion_dict, device):\n",
        "    model.eval()\n",
        "    val_losses = {\"percent_change\": 0, \"current_leg_change\": 0, \"price\": 0, \"total\": 0}\n",
        "    val_metrics = {\"percent_change_acc\": 0, \"current_leg_change_acc\": 0, \"price_mse\": 0}\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for (inputs, crypto_ids), (percent_targets, leg_targets, price_targets) in dataloader:\n",
        "            inputs = inputs.to(device)\n",
        "            crypto_ids = crypto_ids.to(device)\n",
        "            percent_targets = percent_targets.to(device)\n",
        "            leg_targets = leg_targets.to(device)\n",
        "            price_targets = price_targets.to(device)\n",
        "\n",
        "            percent_out, leg_out, price_out = model(inputs, crypto_ids)\n",
        "\n",
        "            loss_percent = criterion_dict['classification'](percent_out, percent_targets)\n",
        "            loss_leg = criterion_dict['classification'](leg_out, leg_targets)\n",
        "            loss_price = criterion_dict['regression'](price_out.squeeze(), price_targets)\n",
        "            total_loss = 0.4 * loss_percent + 0.4 * loss_leg + 0.2 * loss_price\n",
        "\n",
        "            batch_size = inputs.size(0)\n",
        "            total += batch_size\n",
        "\n",
        "            # Update validation losses and metrics\n",
        "            val_losses[\"percent_change\"] += loss_percent.item() * batch_size\n",
        "            val_losses[\"current_leg_change\"] += loss_leg.item() * batch_size\n",
        "            val_losses[\"price\"] += loss_price.item() * batch_size\n",
        "            val_losses[\"total\"] += total_loss.item() * batch_size\n",
        "\n",
        "            _, predicted_percent = torch.max(percent_out, 1)\n",
        "            _, predicted_leg = torch.max(leg_out, 1)\n",
        "            val_metrics[\"percent_change_acc\"] += (predicted_percent == percent_targets).sum().item()\n",
        "            val_metrics[\"current_leg_change_acc\"] += (predicted_leg == leg_targets).sum().item()\n",
        "            val_metrics[\"price_mse\"] += loss_price.item() * batch_size\n",
        "\n",
        "    # Normalize validation metrics\n",
        "    for key in val_losses:\n",
        "        val_losses[key] /= total\n",
        "\n",
        "    val_metrics[\"percent_change_acc\"] /= total\n",
        "    val_metrics[\"current_leg_change_acc\"] /= total\n",
        "    val_metrics[\"price_mse\"] /= total\n",
        "\n",
        "    return val_losses, val_metrics\n",
        "\n",
        "def main():\n",
        "    # Parameters\n",
        "    batch_size = 64\n",
        "    epochs = 20\n",
        "    learning_rate = 0.001\n",
        "    window_size = 60\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Load and preprocess data\n",
        "    preprocessed_data_dir = 'preprocessed_data'\n",
        "    dfs = []\n",
        "    for ticker in os.listdir(preprocessed_data_dir):\n",
        "        ticker_dir = os.path.join(preprocessed_data_dir, ticker)\n",
        "        if os.path.isdir(ticker_dir):\n",
        "            for file in os.listdir(ticker_dir):\n",
        "                if file.endswith('_preprocessed.csv'):\n",
        "                    filepath = os.path.join(ticker_dir, file)\n",
        "                    df = pd.read_csv(filepath)\n",
        "                    df['crypto'] = ticker\n",
        "                    dfs.append(df)\n",
        "\n",
        "    full_df = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "    target_cols = ['percent_change_classification', 'current_leg_change', 'c']\n",
        "    feature_cols = [col for col in full_df.columns if col not in target_cols + ['t', 'crypto']]\n",
        "\n",
        "    # Normalize features\n",
        "    scaler = StandardScaler()\n",
        "    full_df[feature_cols] = scaler.fit_transform(full_df[feature_cols])\n",
        "\n",
        "    full_df.dropna(subset=feature_cols + target_cols, inplace=True)\n",
        "\n",
        "    # Split data into train, validation, and test sets\n",
        "    train_size = int(0.7 * len(full_df))\n",
        "    val_size = int(0.15 * len(full_df))\n",
        "\n",
        "    train_df = full_df.iloc[:train_size]\n",
        "    val_df = full_df.iloc[train_size:train_size+val_size]\n",
        "    test_df = full_df.iloc[train_size+val_size:]\n",
        "\n",
        "    # Create datasets and dataloaders\n",
        "    train_dataset = CryptoDataset(train_df, feature_cols, window_size)\n",
        "    val_dataset = CryptoDataset(val_df, feature_cols, window_size)\n",
        "    test_dataset = CryptoDataset(test_df, feature_cols, window_size)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Initialize model\n",
        "    num_features = len(feature_cols)\n",
        "    num_cryptos = full_df['crypto'].nunique()\n",
        "    num_classes = full_df['percent_change_classification'].nunique()\n",
        "\n",
        "    model = ShortTermTransformerModel(\n",
        "        num_features=num_features,\n",
        "        num_cryptos=num_cryptos,\n",
        "        d_model=256,\n",
        "        nhead=8,\n",
        "        num_encoder_layers=4,\n",
        "        dim_feedforward=512,\n",
        "        num_classes=num_classes,\n",
        "        max_seq_length=window_size\n",
        "    ).to(device)\n",
        "\n",
        "    criterion_dict = {\n",
        "        'classification': nn.CrossEntropyLoss(),\n",
        "        'regression': nn.MSELoss()\n",
        "    }\n",
        "\n",
        "\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    best_model_state = None\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
        "\n",
        "        # Training phase\n",
        "        train_losses, train_metrics = train(model, train_loader, criterion_dict, optimizer, scheduler, device)\n",
        "        print(f\"Training - Losses: {train_losses}\")\n",
        "        print(f\"Training - Metrics: {train_metrics}\")\n",
        "\n",
        "        # Validation phase\n",
        "        val_losses, val_metrics = validate(model, val_loader, criterion_dict, device)\n",
        "        print(f\"Validation - Losses: {val_losses}\")\n",
        "        print(f\"Validation - Metrics: {val_metrics}\")\n",
        "\n",
        "        # Save best model\n",
        "        if val_losses[\"total\"] < best_val_loss:\n",
        "            best_val_loss = val_losses[\"total\"]\n",
        "            best_model_state = model.state_dict().copy()\n",
        "            print(f\"New best model saved with validation loss: {best_val_loss:.4f}\")\n",
        "\n",
        "    # Save the best model\n",
        "    torch.save(best_model_state, 'best_short_term_transformer_model.pth')\n",
        "    print(\"Best model saved as best_short_term_transformer_model.pth\")\n",
        "\n",
        "    # Final evaluation on test set\n",
        "    model.load_state_dict(best_model_state)\n",
        "    test_losses, test_metrics = validate(model, test_loader, criterion_dict, device)\n",
        "    print(\"\\nFinal Test Results:\")\n",
        "    print(f\"Test Losses: {test_losses}\")\n",
        "    print(f\"Test Metrics: {test_metrics}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yz7oFaDq01RB",
        "outputId": "d752d2f4-dbb1-4d28-934d-c6d63b313b9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1970/1970 [07:44<00:00,  4.24it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training - Losses: {'percent_change': 1.879135896520678, 'current_leg_change': 0.010670327523426119, 'price': 523484213.08452255, 'total': 104696844.6572106}\n",
            "Training - Metrics: {'percent_change_acc': 0.19446934420637627, 'current_leg_change_acc': 0.9997461546394206, 'price_mse': 523484213.08452255}\n",
            "Validation - Losses: {'percent_change': 1.8356741777746863, 'current_leg_change': 0.07749582119124374, 'price': 694.9023181696155, 'total': 139.74573369516517}\n",
            "Validation - Metrics: {'percent_change_acc': 0.19983677708943873, 'current_leg_change_acc': 1.0, 'price_mse': 694.9023181696155}\n",
            "New best model saved with validation loss: 139.7457\n",
            "\n",
            "Epoch 2/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1970/1970 [07:46<00:00,  4.23it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training - Losses: {'percent_change': 1.851016315809535, 'current_leg_change': 0.001920481608581799, 'price': 138581312.46104664, 'total': 27716263.531496655}\n",
            "Training - Metrics: {'percent_change_acc': 0.19858639864827346, 'current_leg_change_acc': 1.0, 'price_mse': 138581312.46104664}\n",
            "Validation - Losses: {'percent_change': 1.838019678101552, 'current_leg_change': 0.029525716877268984, 'price': 36756716.040373325, 'total': 7351343.924877539}\n",
            "Validation - Metrics: {'percent_change_acc': 0.20124642949883148, 'current_leg_change_acc': 1.0, 'price_mse': 36756716.040373325}\n",
            "\n",
            "Epoch 3/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|█▉        | 389/1970 [01:31<05:35,  4.71it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NFO9SgDIysEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#OLDER\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "class ShortTermTransformerModel(nn.Module):\n",
        "    def __init__(self, num_features, num_cryptos, d_model=256, nhead=8, num_encoder_layers=4,\n",
        "                 dim_feedforward=512, dropout=0.3, num_classes=3, max_seq_length=50):\n",
        "        super(ShortTermTransformerModel, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.crypto_embedding = nn.Embedding(num_cryptos, d_model)\n",
        "        self.input_linear = nn.Linear(num_features, d_model)\n",
        "        self.batch_norm_input = nn.BatchNorm1d(d_model)\n",
        "\n",
        "        self.pre_transformer_norm = nn.LayerNorm(d_model)\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            dim_feedforward=dim_feedforward,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_encoder_layers)\n",
        "\n",
        "        self.post_transformer_norm = nn.LayerNorm(d_model)\n",
        "        self.batch_norm_output = nn.BatchNorm1d(d_model)\n",
        "\n",
        "        # Only percent_change gets Softmax (classification task)\n",
        "        self.percent_change_head = nn.Sequential(\n",
        "            nn.Linear(d_model, d_model // 2),\n",
        "            nn.LayerNorm(d_model // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(d_model // 2, num_classes),\n",
        "            nn.Softmax(dim=-1)\n",
        "        )\n",
        "\n",
        "        # Leg direction head without Softmax (regression task)\n",
        "        self.leg_direction_head = nn.Sequential(\n",
        "            nn.Linear(d_model, d_model // 2),\n",
        "            nn.LayerNorm(d_model // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(d_model // 2, 1)  # Changed to 1 output for continuous value\n",
        "        )\n",
        "\n",
        "        self.price_prediction_head = nn.Sequential(\n",
        "            nn.Linear(d_model, d_model // 2),\n",
        "            nn.LayerNorm(d_model // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(d_model // 2, 1)\n",
        "        )\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src, crypto_id):\n",
        "        src = self.input_linear(src) * math.sqrt(self.d_model)\n",
        "        crypto_emb = self.crypto_embedding(crypto_id).unsqueeze(1)\n",
        "        src = src + crypto_emb\n",
        "\n",
        "        batch_size, seq_len, feat_dim = src.size()\n",
        "        src = src.view(-1, feat_dim)\n",
        "        src = self.batch_norm_input(src)\n",
        "        src = src.view(batch_size, seq_len, feat_dim)\n",
        "\n",
        "        src = self.pre_transformer_norm(src)\n",
        "        memory = self.transformer_encoder(src)\n",
        "        memory = self.post_transformer_norm(memory)\n",
        "\n",
        "        features = memory[:, -1, :]\n",
        "        features = self.batch_norm_output(features)\n",
        "        features = self.dropout(features)\n",
        "\n",
        "        percent_change = self.percent_change_head(features)\n",
        "        leg_direction = self.leg_direction_head(features)\n",
        "        price_prediction = self.price_prediction_head(features)\n",
        "\n",
        "        return percent_change, leg_direction, price_prediction\n",
        "class CryptoDataset(Dataset):\n",
        "    def __init__(self, dataframe, feature_cols, window_size=60):\n",
        "        self.data = dataframe\n",
        "        self.feature_cols = feature_cols\n",
        "        self.window_size = window_size\n",
        "        self.cryptos = sorted(dataframe['crypto'].unique())\n",
        "        self.crypto_to_id = {crypto: idx for idx, crypto in enumerate(self.cryptos)}\n",
        "        self.crypto_data = {\n",
        "            crypto: dataframe[dataframe['crypto'] == crypto].sort_values('t').reset_index(drop=True)\n",
        "            for crypto in self.cryptos\n",
        "        }\n",
        "\n",
        "        self.indices = []\n",
        "        for crypto in self.cryptos:\n",
        "            data_length = len(self.crypto_data[crypto])\n",
        "            if data_length > self.window_size:\n",
        "                self.indices.extend([(crypto, idx) for idx in range(data_length - self.window_size)])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        crypto, seq_start = self.indices[idx]\n",
        "        data = self.crypto_data[crypto].iloc[seq_start:seq_start + self.window_size]\n",
        "        features = data[self.feature_cols].values\n",
        "\n",
        "        target_idx = seq_start + self.window_size\n",
        "        data_length = len(self.crypto_data[crypto])\n",
        "        if target_idx >= data_length:\n",
        "            target_idx = data_length - 1\n",
        "\n",
        "        percent_change = self.crypto_data[crypto].iloc[target_idx]['percent_change_classification']\n",
        "        leg_direction = self.crypto_data[crypto].iloc[target_idx]['current_leg_change']\n",
        "        price = self.crypto_data[crypto].iloc[target_idx]['c']\n",
        "\n",
        "        crypto_id = self.crypto_to_id[crypto]\n",
        "\n",
        "        return (\n",
        "            (torch.tensor(features, dtype=torch.float32), torch.tensor(crypto_id, dtype=torch.long)),\n",
        "            (\n",
        "                torch.tensor(percent_change, dtype=torch.long),\n",
        "                torch.tensor(leg_direction, dtype=torch.long),\n",
        "                torch.tensor(price, dtype=torch.float32),\n",
        "            ),\n",
        "        )\n",
        "\n",
        "def train(model, dataloader, criterion_dict, optimizer, scheduler, device):\n",
        "    model.train()\n",
        "    epoch_losses = {\"percent_change\": 0, \"current_leg_change\": 0, \"price\": 0, \"total\": 0}\n",
        "    metrics = {\"percent_change_acc\": 0, \"current_leg_change_acc\": 0, \"price_mse\": 0}\n",
        "    total = 0\n",
        "\n",
        "    for (inputs, crypto_ids), (percent_targets, leg_targets, price_targets) in tqdm(dataloader):\n",
        "        inputs = inputs.to(device)\n",
        "        crypto_ids = crypto_ids.to(device)\n",
        "        percent_targets = percent_targets.to(device)\n",
        "        leg_targets = leg_targets.to(device)\n",
        "        price_targets = price_targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        percent_out, leg_out, price_out = model(inputs, crypto_ids)\n",
        "\n",
        "        loss_percent = criterion_dict['classification'](percent_out, percent_targets)\n",
        "        loss_leg = criterion_dict['classification'](leg_out, leg_targets)\n",
        "        loss_price = criterion_dict['regression'](price_out.squeeze(), price_targets)\n",
        "\n",
        "        # Weighted loss combination\n",
        "        total_loss = 0.4 * loss_percent + 0.4 * loss_leg + 0.2 * loss_price\n",
        "        total_loss.backward()\n",
        "        all_grads = []\n",
        "        for p in model.parameters():\n",
        "            if p.grad is not None:\n",
        "                all_grads.extend(p.grad.cpu().numpy().flatten())\n",
        "\n",
        "\n",
        "\n",
        "        # Gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        batch_size = inputs.size(0)\n",
        "        total += batch_size\n",
        "\n",
        "        # Update losses\n",
        "        epoch_losses[\"percent_change\"] += loss_percent.item() * batch_size\n",
        "        epoch_losses[\"current_leg_change\"] += loss_leg.item() * batch_size\n",
        "        epoch_losses[\"price\"] += loss_price.item() * batch_size\n",
        "        epoch_losses[\"total\"] += total_loss.item() * batch_size\n",
        "\n",
        "        # Update metrics\n",
        "        _, predicted_percent = torch.max(percent_out, 1)\n",
        "        _, predicted_leg = torch.max(leg_out, 1)\n",
        "        metrics[\"percent_change_acc\"] += (predicted_percent == percent_targets).sum().item()\n",
        "        metrics[\"current_leg_change_acc\"] += (predicted_leg == leg_targets).sum().item()\n",
        "        metrics[\"price_mse\"] += loss_price.item() * batch_size\n",
        "    plt.hist(all_grads, bins=50)\n",
        "    plt.title(\"Distribution of Gradients\")\n",
        "    plt.xlabel(\"Gradient Value\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.show()\n",
        "    # Normalize metrics\n",
        "    for key in epoch_losses:\n",
        "        epoch_losses[key] /= total\n",
        "\n",
        "    metrics[\"percent_change_acc\"] /= total\n",
        "    metrics[\"current_leg_change_acc\"] /= total\n",
        "    metrics[\"price_mse\"] /= total\n",
        "\n",
        "    # Update learning rate scheduler\n",
        "    scheduler.step(epoch_losses[\"total\"])\n",
        "\n",
        "    return epoch_losses, metrics\n",
        "\n",
        "def validate(model, dataloader, criterion_dict, device):\n",
        "    model.eval()\n",
        "    val_losses = {\"percent_change\": 0, \"current_leg_change\": 0, \"price\": 0, \"total\": 0}\n",
        "    val_metrics = {\"percent_change_acc\": 0, \"current_leg_change_acc\": 0, \"price_mse\": 0}\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for (inputs, crypto_ids), (percent_targets, leg_targets, price_targets) in dataloader:\n",
        "            inputs = inputs.to(device)\n",
        "            crypto_ids = crypto_ids.to(device)\n",
        "            percent_targets = percent_targets.to(device)\n",
        "            leg_targets = leg_targets.to(device)\n",
        "            price_targets = price_targets.to(device)\n",
        "\n",
        "            percent_out, leg_out, price_out = model(inputs, crypto_ids)\n",
        "\n",
        "            loss_percent = criterion_dict['classification'](percent_out, percent_targets)\n",
        "            loss_leg = criterion_dict['classification'](leg_out, leg_targets)\n",
        "            loss_price = criterion_dict['regression'](price_out.squeeze(), price_targets)\n",
        "            total_loss = 0.4 * loss_percent + 0.4 * loss_leg + 0.2 * loss_price\n",
        "\n",
        "            batch_size = inputs.size(0)\n",
        "            total += batch_size\n",
        "\n",
        "            # Update validation losses and metrics\n",
        "            val_losses[\"percent_change\"] += loss_percent.item() * batch_size\n",
        "            val_losses[\"current_leg_change\"] += loss_leg.item() * batch_size\n",
        "            val_losses[\"price\"] += loss_price.item() * batch_size\n",
        "            val_losses[\"total\"] += total_loss.item() * batch_size\n",
        "\n",
        "            _, predicted_percent = torch.max(percent_out, 1)\n",
        "            _, predicted_leg = torch.max(leg_out, 1)\n",
        "            val_metrics[\"percent_change_acc\"] += (predicted_percent == percent_targets).sum().item()\n",
        "            val_metrics[\"current_leg_change_acc\"] += (predicted_leg == leg_targets).sum().item()\n",
        "            val_metrics[\"price_mse\"] += loss_price.item() * batch_size\n",
        "\n",
        "    # Normalize validation metrics\n",
        "    for key in val_losses:\n",
        "        val_losses[key] /= total\n",
        "\n",
        "    val_metrics[\"percent_change_acc\"] /= total\n",
        "    val_metrics[\"current_leg_change_acc\"] /= total\n",
        "    val_metrics[\"price_mse\"] /= total\n",
        "\n",
        "    return val_losses, val_metrics\n",
        "\n",
        "def main():\n",
        "    # Parameters\n",
        "    batch_size = 64\n",
        "    epochs = 20\n",
        "    learning_rate = 0.001\n",
        "    window_size = 60\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Load and preprocess data\n",
        "    preprocessed_data_dir = 'preprocessed_data'\n",
        "    dfs = []\n",
        "    for ticker in os.listdir(preprocessed_data_dir):\n",
        "        ticker_dir = os.path.join(preprocessed_data_dir, ticker)\n",
        "        if os.path.isdir(ticker_dir):\n",
        "            for file in os.listdir(ticker_dir):\n",
        "                if file.endswith('_preprocessed.csv'):\n",
        "                    filepath = os.path.join(ticker_dir, file)\n",
        "                    df = pd.read_csv(filepath)\n",
        "                    df['crypto'] = ticker\n",
        "                    dfs.append(df)\n",
        "\n",
        "    full_df = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "    target_cols = ['percent_change_classification', 'current_leg_change', 'c']\n",
        "    feature_cols = [col for col in full_df.columns if col not in target_cols + ['t', 'crypto']]\n",
        "\n",
        "    # Normalize features\n",
        "    scaler = StandardScaler()\n",
        "    full_df[feature_cols] = scaler.fit_transform(full_df[feature_cols])\n",
        "\n",
        "    full_df.dropna(subset=feature_cols + target_cols, inplace=True)\n",
        "\n",
        "    # Split data into train, validation, and test sets\n",
        "    train_size = int(0.7 * len(full_df))\n",
        "    val_size = int(0.15 * len(full_df))\n",
        "\n",
        "    train_df = full_df.iloc[:train_size]\n",
        "    val_df = full_df.iloc[train_size:train_size+val_size]\n",
        "    test_df = full_df.iloc[train_size+val_size:]\n",
        "\n",
        "    # Create datasets and dataloaders\n",
        "    train_dataset = CryptoDataset(train_df, feature_cols, window_size)\n",
        "    val_dataset = CryptoDataset(val_df, feature_cols, window_size)\n",
        "    test_dataset = CryptoDataset(test_df, feature_cols, window_size)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Initialize model\n",
        "    num_features = len(feature_cols)\n",
        "    num_cryptos = full_df['crypto'].nunique()\n",
        "    num_classes = full_df['percent_change_classification'].nunique()\n",
        "\n",
        "    model = ShortTermTransformerModel(\n",
        "        num_features=num_features,\n",
        "        num_cryptos=num_cryptos,\n",
        "        d_model=256,\n",
        "        nhead=8,\n",
        "        num_encoder_layers=4,\n",
        "        dim_feedforward=512,\n",
        "        num_classes=num_classes,\n",
        "        max_seq_length=window_size\n",
        "    ).to(device)\n",
        "\n",
        "    criterion_dict = {\n",
        "        'classification': nn.CrossEntropyLoss(),\n",
        "        'regression': nn.MSELoss()\n",
        "    }\n",
        "\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    best_model_state = None\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
        "\n",
        "        # Training phase\n",
        "        train_losses, train_metrics = train(model, train_loader, criterion_dict, optimizer, scheduler, device)\n",
        "        print(f\"Training - Losses: {train_losses}\")\n",
        "        print(f\"Training - Metrics: {train_metrics}\")\n",
        "\n",
        "        # Validation phase\n",
        "        val_losses, val_metrics = validate(model, val_loader, criterion_dict, device)\n",
        "        print(f\"Validation - Losses: {val_losses}\")\n",
        "        print(f\"Validation - Metrics: {val_metrics}\")\n",
        "\n",
        "        # Save best model\n",
        "        if val_losses[\"total\"] < best_val_loss:\n",
        "            best_val_loss = val_losses[\"total\"]\n",
        "            best_model_state = model.state_dict().copy()\n",
        "            print(f\"New best model saved with validation loss: {best_val_loss:.4f}\")\n",
        "\n",
        "    # Save the best model\n",
        "    torch.save(best_model_state, 'best_short_term_transformer_model.pth')\n",
        "    print(\"Best model saved as best_short_term_transformer_model.pth\")\n",
        "\n",
        "    # Final evaluation on test set\n",
        "    model.load_state_dict(best_model_state)\n",
        "    test_losses, test_metrics = validate(model, test_loader, criterion_dict, device)\n",
        "    print(\"\\nFinal Test Results:\")\n",
        "    print(f\"Test Losses: {test_losses}\")\n",
        "    print(f\"Test Metrics: {test_metrics}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "r9z7tV9nvqz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install matplotlib"
      ],
      "metadata": {
        "id": "LvckC2_VHNGh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "285b4d2a-3a82-47b3-966a-47d0655755d5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-learn torch numpy pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xPFW_10CXUe",
        "outputId": "07c8d5c8-568e-4177-8394-b67361879029"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    }
  ]
}